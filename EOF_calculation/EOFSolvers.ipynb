{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b9e958",
   "metadata": {},
   "source": [
    "#### Sequential Feature Selection of PCs for Random Forest model using PV/GPH/EHF as input.\n",
    "\n",
    "File duplicated on May 8, 2025.\n",
    "\n",
    "File editted on June 4th. Updated to use new timeseries of data for temperature. Also attempting to remove necessity for multiple solvers by timeseries. \n",
    "\n",
    "This specific file is for the \"real\" analysis and will not have different PCs depending on leadtimes. \n",
    "\n",
    "I would like to identify the # of nodes that represent >80% of the variance for each feature. Then, I will do two models.  \n",
    "\n",
    "FILE COPIED FROM REPO 1/5/2026 TO CONDUCT SEPARATION ON DATA AND EOF ANALYSIS BASED ON TRAIN/TEST SPLIT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57a19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant import statements\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "##just to stop the excess number of warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import randint, sample, seed\n",
    "\n",
    "# plotting related imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  # statistical data visualization\n",
    "import xarray as xr\n",
    "\n",
    "from eofs.standard import Eof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70e1ac",
   "metadata": {},
   "source": [
    "The bulk of this file to start is copied from the previous EOF file/my EOF test file. \n",
    "\n",
    "##### First, I am going to pickle in the input data. I will then remove the seasonal climo from the dataset...\n",
    "\n",
    "I had to actually download the data locally and upload it here to the H100 cluster in the ./Dissertation_Coding/data folder because I could not call it from my home directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3f81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input data\n",
    "infile = open(\"../processed_vertical_data/vertanom_u.p\",\"rb\",)\n",
    "u_input = pickle.load(infile)  ##vertical U cross section\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../processed_vertical_data/vertanom_ehf.p\",\"rb\",)\n",
    "ehf_input = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../processed_vertical_data/vertanom_gph.p\",\"rb\",)\n",
    "gph_input = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb107e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 182, 37, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_input.shape  ##62 years, october through march,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e3f618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 182, 37, 180)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gph_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe7c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 182, 37, 180)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehf_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b3da6",
   "metadata": {},
   "source": [
    "#### Great, so I have everything uploaded and reduced to daily anomalies with the seasonal climo removed. Fantastic, lol. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205fe90",
   "metadata": {},
   "source": [
    "##### Attempt at EOF analysis/PC decomp based on Zheng's example code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e60d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 DAYS TRAIN\n",
      "(7748, 37, 36)\n",
      "(7748, 37, 180)\n",
      "(7748, 37, 180)\n"
     ]
    }
   ],
   "source": [
    "print('14 DAYS TRAIN')\n",
    "##flatten array to just the dates relevant to my models. \n",
    "flat_u_14 = u_input[:52, 19:168, :, :].reshape((52 * 149, 37, 36))\n",
    "print(flat_u_14.shape)\n",
    "\n",
    "flat_EHF_14 = ehf_input[:52, 19:168, :, :].reshape((52 * 149, 37, 180))\n",
    "print(flat_EHF_14.shape)\n",
    "\n",
    "flat_GPH_14= gph_input[:52, 19:168, :, :].reshape((52 * 149, 37, 180))\n",
    "print(flat_GPH_14.shape)\n",
    "\n",
    "Usolver_14_train = Eof(flat_u_14)\n",
    "EHFsolver_14_train = Eof(flat_EHF_14)\n",
    "GPHsolver_14_train = Eof(flat_GPH_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a93b198-07cd-4e1e-bbae-b50b9dcb2e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 DAYS TEST\n",
      "(1490, 37, 36)\n",
      "(1490, 37, 180)\n",
      "(1490, 37, 180)\n"
     ]
    }
   ],
   "source": [
    "print('14 DAYS TEST')\n",
    "##flatten array to just the dates relevant to my models. \n",
    "flat_u_14 = u_input[52:, 19:168, :, :].reshape((10 * 149, 37, 36))\n",
    "print(flat_u_14.shape)\n",
    "\n",
    "flat_EHF_14 = ehf_input[52:, 19:168, :, :].reshape((10 * 149, 37, 180))\n",
    "print(flat_EHF_14.shape)\n",
    "\n",
    "flat_GPH_14= gph_input[52:, 19:168, :, :].reshape((10 * 149, 37, 180))\n",
    "print(flat_GPH_14.shape)\n",
    "\n",
    "Usolver_14_test = Eof(flat_u_14)\n",
    "EHFsolver_14_test = Eof(flat_EHF_14)\n",
    "GPHsolver_14_test = Eof(flat_GPH_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc1b5c0-51c8-438b-96dd-4a89cda7e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only the training solvers are saved out so that these PCs can be extrapolated onto the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24a7e576-c2ed-492f-8b0d-d731b7c1b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Usolver_14_train, open(\"Usolver_14_train.p\", 'wb'))\n",
    "pickle.dump(EHFsolver_14_train, open(\"EHFsolver_14_train.p\", 'wb'))\n",
    "pickle.dump(GPHsolver_14_train, open(\"GPHsolver_14_train.p\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 AI Environment",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
