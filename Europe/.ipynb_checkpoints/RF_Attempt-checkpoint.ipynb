{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06200813",
   "metadata": {},
   "source": [
    "### Random Forests for my ellipse metric-based model. \n",
    "\n",
    "Updated 4/11/2025 to do 14-day instead of 10. \n",
    "\n",
    "Now updating AGAIN on 4/16/2025 to add in appropriate skill scores... lol. \n",
    "\n",
    "I uploaded this to my remote repo on 7/8/2025. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "31dca689",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496993ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant import statements\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##just to stop the excess number of warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import definitions from skill stat file\n",
    "from SkillStats_MOD import BSS\n",
    "from SkillStats_MOD import RAS\n",
    "from SkillStats_MOD import PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e59445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load input data, it is max/min standardized, NaNs removed\n",
    "#stratospheric polar vortex ellipse diagnostics from Fernandez et al 2025 (in review)\n",
    "#comparison here may be a little muddled because I am limitied in the days that I can observe, however, I am currently working(7/8/2025) on calculating the diagnostics for the full dataset\n",
    "#this will be fixed. \n",
    "\n",
    "infile = open(\"../data/nolag_extendedanom_input.p\", 'rb') \n",
    "nolag_input = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "nolag_input.shape\n",
    "##leap day removed, only November 1 through march 31st. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0303d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 149"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a080d",
   "metadata": {},
   "source": [
    "If I go back to the OG code, this was all 137 instead of 149. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7267540",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = np.empty((62,idx,8)) #create new input array, 14 day lag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c349441",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reshaping to change lag in metrics for input\n",
    "inp1[:,:,0] = nolag_input[:62,:,0] ##wind\n",
    "inp1[:,:,1] = nolag_input[:62,:,1] ##ratio\n",
    "inp1[:,:,2] = nolag_input[:62,:,2] ##latitude\n",
    "inp1[:,:,3] = nolag_input[:62,:,3] ##longitude\n",
    "inp1[:,:,4] = nolag_input[:62,:,4] ##size\n",
    "inp1[:,:,5] = nolag_input[:62,:,5] ##ephi\n",
    "inp1[:,:,6] = nolag_input[:62,:,6] ##gph\n",
    "inp1[:,:,7] = nolag_input[:62,:,7] ##pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=inp1.reshape(62*idx,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load output data file.\n",
    "#I can change this to represent any of the available temp regions. \n",
    "infile = open(\"../data/eur_anomtemps_reduced.p\",\"rb\",)\n",
    "temp = pickle.load(infile) \n",
    "infile.close()\n",
    "\n",
    "# load climo data\n",
    "infile = open(\"../data/eur_climoprob_reduced.p\",\"rb\",)\n",
    "climo = pickle.load(infile) \n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)\n",
    "print(climo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.reshape(62,149) ##it was flattened, reshape it\n",
    "climo = climo.reshape(62,149,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reshape again to introduce lag. \n",
    "output = temp[:,:].reshape(62*idx)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reshaping climo\n",
    "climo = climo[:,:,:].reshape(62*idx,2)\n",
    "climo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pandas dataframe\n",
    "input = pd.DataFrame(inp)\n",
    "#label columns of variables for input data\n",
    "col_names = ['wind','rat','cenlat','cenlon','size','ephi','gph','pv']\n",
    "input.columns = col_names\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(input.corr(), annot=True) ##heatmap for showing correlation across variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f58c5",
   "metadata": {},
   "source": [
    "### Start Random Forest Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47029752",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first ... split data into training/testing ...\n",
    "##this is just taking the first 58 years of data, leaving the remaining 5 for testing\n",
    "X_train = input.iloc[:(57*idx),:]\n",
    "X_test = input.iloc[(57*idx):,:]\n",
    "Y_train = output[:(57*idx)]\n",
    "Y_test = output[(57*idx):]\n",
    "\n",
    "val_subset = (5*idx) #index for subsetting validation data in cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16de14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b781dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##next are some empty lists, as I love to do lol. \n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce04cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists to save Accuracy\n",
    "acc_reg1_val = []\n",
    "acc_reg1_train = []\n",
    "acc_reg1_test = []\n",
    "\n",
    "##BSS Arrays, all of the skill scores have 200 rows\n",
    "#because that is how many cross-validations I will do for the model\n",
    "BSS_all= np.empty((n,))\n",
    "BSS_val= np.empty((n,))\n",
    "BSS_train= np.empty((n,))\n",
    "BSS_test= np.empty((n,))\n",
    "\n",
    "##RAS and PAS Arrays\n",
    "Prec_all= np.empty((n,2))\n",
    "Rec_all= np.empty((n,2))\n",
    "\n",
    "Prec_val= np.empty((n,2))\n",
    "Rec_val= np.empty((n,2))\n",
    "\n",
    "Prec_train= np.empty((n,2))\n",
    "Rec_train= np.empty((n,2))\n",
    "\n",
    "Prec_test= np.empty((n,2))\n",
    "Rec_test= np.empty((n,2))\n",
    "\n",
    "important = np.empty((n,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df41c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save probabilities\n",
    "p_test = []\n",
    "p_train = []\n",
    "p_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create initial regressor for rf to do feature selection \n",
    "rf_reg1 = RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92c2f3",
   "metadata": {},
   "source": [
    "In order for me to add in the appropriate skill scores, since this is a categorical classification, I had to create separate metrics with one hot encoding to calculate BSS/RAS/PAS. \n",
    "\n",
    "I also had to calculate the daily probability for each categorical classification, which is done in the temperature pre-processing file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab40e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##one-hot encoded outputs for the purpose of calculating probabilities\n",
    "import keras\n",
    "Y_all = keras.utils.to_categorical(output)\n",
    "Y_tes = keras.utils.to_categorical(Y_test)\n",
    "X_all = input.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beec581",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223810f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make loop for cross validation \n",
    "for l in range(0,n):\n",
    "    print(\"Cross Val #:\"+str(l))\n",
    "    ##randomly choose a fraction of events for validation and training\n",
    "    start = random.randrange(len(X_train.iloc[:,0])-val_subset)\n",
    "    end = start+(val_subset)\n",
    "\n",
    "    climo_test = climo[(57*idx):,:]\n",
    "    climo_tr = climo[:(57*idx),:]\n",
    "    \n",
    "    X_val = input.iloc[start:end,:]\n",
    "    Y_val = output[start:end]\n",
    "    climo_val = climo_tr[start:end,:]\n",
    "    \n",
    "    X_train1 = X_train.iloc[0:start]\n",
    "    Y_train1 = Y_train[0:start]\n",
    "    climo_train1 = climo_tr[0:start,:]\n",
    "    X_train2 = X_train.iloc[end:]\n",
    "    Y_train2 = Y_train[end:]\n",
    "    climo_train2 = climo_tr[end:,:]\n",
    "\n",
    "    ##concatenate all of these\n",
    "    X_tr = pd.concat([X_train1,X_train2], axis = 0)\n",
    "    Y_tr = np.concatenate((Y_train1,Y_train2))\n",
    "    climo_train = np.concatenate((climo_train1,climo_train2))\n",
    "    \n",
    "\n",
    "    #_______________________train the model_______________________________\n",
    "    #train rf\n",
    "    rf_reg1.fit(X_tr, Y_tr)\n",
    "    pred1 = rf_reg1.predict(X_all)\n",
    "    pred2 = rf_reg1.predict_proba(X_all)\n",
    "    \n",
    "    #prediction with validation data\n",
    "    pred_val1 = rf_reg1.predict(X_val)\n",
    "    pred_val2 = rf_reg1.predict_proba(X_val)\n",
    "    p_val.append(pred_val2)\n",
    "    acc_reg1_val.append(accuracy_score(Y_val, pred_val1))\n",
    "    \n",
    "    #prediction with training data\n",
    "    pred_train1 = rf_reg1.predict(X_tr)\n",
    "    pred_train2 = rf_reg1.predict_proba(X_tr)\n",
    "    p_train.append(pred_train2)\n",
    "    acc_reg1_train.append(accuracy_score(Y_tr, pred_train1))\n",
    "\n",
    "    #prediction with testing data\n",
    "    pred_test1 = rf_reg1.predict(X_test)\n",
    "    pred_test2 = rf_reg1.predict_proba(X_test)\n",
    "    p_test.append(pred_test2)\n",
    "    acc_reg1_test.append(accuracy_score(Y_test, pred_test1))\n",
    "   \n",
    "    #_______________________feature selection______________________________\n",
    "    #prepare to show relevant features by actually ... choosing them \n",
    "    selector = SelectFromModel(rf_reg1, threshold=\"mean\", max_features=None)\n",
    "    X_train_selected = selector.transform(X_tr)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    #print names of selected features\n",
    "    selected_features = input.columns[selector.get_support()]\n",
    "    print(f'Selected Features: {selected_features}')\n",
    "\n",
    "    importances = rf_reg1.feature_importances_\n",
    "    important[l,:] = importances[:]\n",
    "    \n",
    "    #_______________________statistics calcs_______________________________\n",
    "    pred_class = []\n",
    "    predval_class = []\n",
    "    predtr_class = []\n",
    "    predtest_class = []\n",
    "    \n",
    "    Y_tr2 = keras.utils.to_categorical(Y_tr)\n",
    "    Y_val2 = keras.utils.to_categorical(Y_val)\n",
    "\n",
    "    ##BRIER SKILL SCORE\n",
    "    BSS_all[l] = BSS(Y_all,pred2)\n",
    "    BSS_val[l] = BSS(Y_val2,pred_val2)\n",
    "    BSS_train[l] = BSS(Y_tr2,pred_train2)\n",
    "    BSS_test[l] = BSS(Y_tes,pred_test2) \n",
    "    \n",
    "    ##RECALL ACCURACY SCORE    \n",
    "    RAS(l, Rec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Rec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Rec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Rec_test, Y_tes, pred_test2, predtest_class)\n",
    "    ##PRECISION ACCURACY SCORE     \n",
    "    PAS(l, Prec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Prec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Prec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Prec_test, Y_tes, pred_test2, predtest_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7684f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('###################################################')\n",
    "print(f'Accuracy, Validation: {np.mean(acc_reg1_val) * 100:.2f}%')\n",
    "print(f'Accuracy, Training: {np.mean(acc_reg1_train) * 100:.2f}%')\n",
    "print(f'Accuracy, Testing: {np.mean(acc_reg1_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "font = 16\n",
    "#loop through each member\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ticks = ['Full', 'Train', 'Val', 'Test'] #set tick numbers for dataset\n",
    "colors = ['lightcyan','indianred']\n",
    "ind = [2, 4, 6, 8]  # the x locations for the groups\n",
    "w = 0.3 #box-plot width\n",
    "labels = ['- Anom', '+ Anom '] #labels of quantiles\n",
    "\n",
    "\n",
    "##begin to go plot by plot ...\n",
    "#each plot has a separate plot function for each lead time. In these, the plots get each quantile plotted. \n",
    "plt.suptitle(\"Stat Scores for Predicting Sign of Europe Temp Anoms in Full RF Model at 14-days Leadtime\",fontsize = 18) \n",
    "\n",
    "a1_0 = ax1.boxplot(BSS_all[:], positions= [2], widths=w, patch_artist=True)\n",
    "a1_5 = ax1.boxplot(BSS_train[:], positions=[4], widths=w, patch_artist=True)\n",
    "a1_10 = ax1.boxplot(BSS_val[:], positions=[6], widths=w, patch_artist=True)\n",
    "a1_14 = ax1.boxplot(BSS_test[:], positions=[7], widths=w, patch_artist=True)\n",
    "ax1.axhline(0, c='k', ls ='-.')\n",
    "ax1.set_xticks(ind, ticks)\n",
    "#next few lines color the box plot faces\n",
    "for bplot in (a1_0, a1_5, a1_10, a1_14,):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "#for patch, label in zip(a1_0['boxes'], labels):\n",
    "    #patch.set_label(label)\n",
    "ax1.set_title('BSS for Temperature Region',fontsize = 14)\n",
    "ax1.set_ylim(-0.1,0.25)\n",
    "ax1.set_xlabel('Data Set',fontsize = 14)\n",
    "ax1.set_ylabel('BSS',fontsize = font)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax1.legend(loc = 'lower right', fontsize = 10)\n",
    "ax1.set_aspect('auto') ;\n",
    "\n",
    "##repeat the process\n",
    "a2_0 = ax2.boxplot([Rec_all[:,0],Rec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a2_5 = ax2.boxplot([Rec_train[:,0],Rec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a2_10 = ax2.boxplot([Rec_val[:,0],Rec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a2_14 = ax2.boxplot([Rec_test[:,0],Rec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax2.axhline(0.5, c='k', ls ='-.')\n",
    "ax2.set_xticks(ind, ticks)\n",
    "for bplot in (a2_0, a2_5, a2_10, a2_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a2_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax2.set_title('RAS for Temperature Region',fontsize = 14)\n",
    "ax2.set_ylim(-0.1,1.1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax2.set_ylabel('RAS',fontsize = font)\n",
    "#ax2.set_xlabel('Data Set',fontsize = 14)\n",
    "#ax2.set_ylabel('Brier Skill Score')\n",
    "ax2.legend(loc = 'lower right', fontsize = 14)\n",
    "ax2.set_aspect('auto') ;\n",
    "\n",
    "a3_0 = ax3.boxplot([Prec_all[:,0],Prec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a3_5 = ax3.boxplot([Prec_train[:,0],Prec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a3_10 = ax3.boxplot([Prec_val[:,0],Prec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a3_14 = ax3.boxplot([Prec_test[:,0],Prec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax3.axhline(0.5, c='k', ls ='-.')\n",
    "ax3.set_xticks(ind, ticks)\n",
    "for bplot in (a3_0, a3_5, a3_10, a3_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a3_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax3.set_title('RAS Well')\n",
    "#ax3.set_title('PAS for Temperature Region',fontsize = 14)\n",
    "ax3.set_ylim(-0.1,1.1)\n",
    "ax3.set_ylabel('PAS',fontsize = font)\n",
    "ax3.set_xlabel('Data Set',fontsize = font)\n",
    "#ax3.set_ylabel('Recall Accuracy Score',fontsize = 14)\n",
    "ax3.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax3.legend(loc = 'lower right', fontsize = 14)\n",
    "ax3.set_aspect('auto') ;\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"./images/FullRF_14days_StatScore.png\", bbox_inches='tight',dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b52934",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array(p_test)\n",
    "p_test = p_test.reshape((len(p_test)*len(p_test[0]),2))\n",
    "\n",
    "p_train = np.array(p_train)\n",
    "p_train = p_train.reshape((len(p_train)*len(p_train[0]),2))\n",
    "\n",
    "p_val= np.array(p_val)\n",
    "p_val = p_val.reshape((len(p_val)*len(p_val[0]),2))\n",
    "\n",
    "bins = np.linspace(0, 1, 37)  #10 bins from 0.4 to 1\n",
    "fs = 11\n",
    "##bin the probabilities\n",
    "counts_neg_train, edges_neg_train = np.histogram(p_train[:,0], bins=bins)\n",
    "counts_pos_train, edges_pos_train = np.histogram(p_train[:,1], bins=bins)\n",
    "\n",
    "counts_neg_val, edges_neg_val = np.histogram(p_val[:,0], bins=bins)\n",
    "counts_pos_val, edges_pos_val = np.histogram(p_val[:,1], bins=bins)\n",
    "\n",
    "counts_neg_test, edges_neg_test = np.histogram(p_test[:,0], bins=bins)\n",
    "counts_pos_test, edges_pos_test = np.histogram(p_test[:,1], bins=bins)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(11,11))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "\n",
    "ax1.bar(edges_neg_train[:-1], counts_neg_train, width=np.diff(edges_neg_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "ax1.set_title('Negative', fontsize=fs+2)\n",
    "ax1.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "ax1.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax2.bar(edges_pos_train[:-1], counts_pos_train, width=np.diff(edges_pos_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "ax2.set_title('Positive', fontsize=fs+2)\n",
    "ax2.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "#ax2.set_ylabel('Count')\n",
    "\n",
    "ax3.bar(edges_neg_val[:-1], counts_neg_val, width=np.diff(edges_neg_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax3.set_title('Negative Validation Predictions', fontsize=fs)\n",
    "ax3.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "ax3.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax4.bar(edges_pos_val[:-1], counts_pos_val, width=np.diff(edges_pos_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax4.set_title('Positive Validation Predictions', fontsize=fs)\n",
    "ax4.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "#ax4.set_ylabel('Count')\n",
    "\n",
    "ax5.bar(edges_neg_test[:-1], counts_neg_test, width=np.diff(edges_neg_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax5.set_title('Negative Testing Predictions', fontsize=fs)\n",
    "ax5.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "ax5.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax6.bar(edges_pos_test[:-1], counts_pos_test, width=np.diff(edges_pos_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax6.set_title('Positive Testing Predictions', fontsize=fs)\n",
    "ax6.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "#ax6.set_ylabel('Count')\n",
    "\n",
    "plt.suptitle(\"Probability Distributions of Various Datasets Across 100 CVs for Predicting +14 day European Temp Anomalies, FM\", fontsize=fs+4, x=0.525,y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/RF_probdistrib_14days.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take average across all feature importance values by cross validation\n",
    "imp = np.nanmean(important, axis = 0)\n",
    "imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ef876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot features by relative importance\n",
    "indices = np.argsort(imp)[::-1]  #sort by importance\n",
    "c = [\"navy\",\"royalblue\",\"slateblue\",\"blueviolet\",\"darkviolet\",\"purple\",\"mediumvioletred\",\"magenta\"]\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(\"Average Feature Importances Across 100 CVs, Europe 14\",fontsize =18)\n",
    "plt.barh(range(input.shape[1]), imp[indices], align=\"center\", color = c)\n",
    "plt.yticks(range(input.shape[1]), input.columns[indices],fontsize =14)\n",
    "plt.xticks(fontsize =14)\n",
    "plt.xlabel(\"Relative Importance\",fontsize =16)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"./images/RF_FeatureImportance_14days.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b770d91",
   "metadata": {},
   "source": [
    "### Switch over to the reduced model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5502efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##change pandas dataframe to choose top 3 important features only\n",
    "input2 = input[['size', \"cenlat\", \"cenlon\",\"gph\"]]\n",
    "#input2 = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGAIN, empty lists \n",
    "n = 100\n",
    "#empty lists to save Accuracy\n",
    "acc_reg2_val = []\n",
    "acc_reg2_train = []\n",
    "acc_reg2_test = []\n",
    "\n",
    "##BSS Arrays\n",
    "##BSS Arrays, all of the skill scores have 200 rows\n",
    "#because that is how many cross-validations I will do for the model\n",
    "BSS_all= np.empty((n,))\n",
    "BSS_val= np.empty((n,))\n",
    "BSS_train= np.empty((n,))\n",
    "BSS_test= np.empty((n,))\n",
    "\n",
    "##RAS and PAS Arrays\n",
    "Prec_all= np.empty((n,2))\n",
    "Rec_all= np.empty((n,2))\n",
    "\n",
    "Prec_val= np.empty((n,2))\n",
    "Rec_val= np.empty((n,2))\n",
    "\n",
    "Prec_train= np.empty((n,2))\n",
    "Rec_train= np.empty((n,2))\n",
    "\n",
    "Prec_test= np.empty((n,2))\n",
    "Rec_test= np.empty((n,2))\n",
    "\n",
    "important = np.empty((n,8))\n",
    "\n",
    "#save PREDICTIONS\n",
    "test90_acc = []\n",
    "##full model\n",
    "fulltest_acc = []\n",
    "\n",
    "##correct positive\n",
    "posXtest = []\n",
    "#false positive\n",
    "FposXtest = []\n",
    "#correct negative\n",
    "negXtest = []\n",
    "#false negative\n",
    "FnegXtest = []\n",
    "\n",
    "indexes = []\n",
    "\n",
    "##correct positive\n",
    "percpos = []\n",
    "#false positive\n",
    "percFpos = []\n",
    "#correct negative\n",
    "percneg = []\n",
    "#false negative\n",
    "percFneg = []\n",
    "\n",
    "#save probabilities\n",
    "p_test = []\n",
    "p_train = []\n",
    "p_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c995467",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first ... split data into training/testing ...\n",
    "##this is just taking the first 58 years of data, leaving the remaining 5 for testing\n",
    "X_train = input2.iloc[:(57*149),:]\n",
    "X_test = input2.iloc[(57*149):,:]\n",
    "Y_train = output[:(57*149)]\n",
    "Y_test = output[(57*149):]\n",
    "\n",
    "val_subset = (5*149) #index for subsetting validation data in cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##definition statement for ACC\n",
    "def calculate_accuracy(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b51d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = keras.utils.to_categorical(output)\n",
    "Y_tes = keras.utils.to_categorical(Y_test)\n",
    "X_all = input2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second random forest model with selected features only\n",
    "rf_reg2 = RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329c700",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make loop for cross validation \n",
    "for l in range(0,n):\n",
    "    print(\"Cross Val #:\"+str(l))\n",
    "    ##randomly choose a fraction of events for validation and training\n",
    "    start = random.randrange(len(X_train.iloc[:,0])-val_subset)\n",
    "    end = start+(val_subset)\n",
    "\n",
    "    climo_test = climo[(57*149):,:]\n",
    "    climo_tr = climo[:(57*149),:]\n",
    "    \n",
    "    X_val = input2.iloc[start:end,:]\n",
    "    Y_val = output[start:end]\n",
    "    climo_val = climo_tr[start:end,:]\n",
    "    \n",
    "    X_train1 = X_train.iloc[0:start]\n",
    "    Y_train1 = Y_train[0:start]\n",
    "    climo_train1 = climo_tr[0:start,:]\n",
    "    X_train2 = X_train.iloc[end:]\n",
    "    Y_train2 = Y_train[end:]\n",
    "    climo_train2 = climo_tr[end:,:]\n",
    "\n",
    "    ##concatenate all of these\n",
    "    X_tr = pd.concat([X_train1,X_train2], axis = 0)\n",
    "    Y_tr = np.concatenate((Y_train1,Y_train2))\n",
    "    climo_train = np.concatenate((climo_train1,climo_train2))\n",
    "    \n",
    "    \n",
    "    #_______________________train the model_______________________________\n",
    "    #train rf\n",
    "    rf_reg2.fit(X_tr, Y_tr)\n",
    "    pred1 = rf_reg2.predict(X_all)\n",
    "    pred2 = rf_reg2.predict_proba(X_all)\n",
    "    \n",
    "    #prediction with validation data\n",
    "    pred_val1 = rf_reg2.predict(X_val)\n",
    "    pred_val2 = rf_reg2.predict_proba(X_val)\n",
    "    p_val.append(pred_val2)\n",
    "    acc_reg2_val.append(accuracy_score(Y_val, pred_val1))\n",
    "    \n",
    "    #prediction with training data\n",
    "    pred_train1 = rf_reg2.predict(X_tr)\n",
    "    pred_train2 = rf_reg2.predict_proba(X_tr)\n",
    "    p_train.append(pred_train2)\n",
    "    acc_reg2_train.append(accuracy_score(Y_tr, pred_train1))\n",
    "\n",
    "    #prediction with testing data\n",
    "    pred_test1 = rf_reg2.predict(X_test)\n",
    "    pred_test2 = rf_reg2.predict_proba(X_test)\n",
    "    p_test.append(pred_test2)\n",
    "    acc_reg2_test.append(accuracy_score(Y_test, pred_test1))\n",
    "    \n",
    "    #_______________________statistics calcs_______________________________\n",
    "    pred_class = []\n",
    "    predval_class = []\n",
    "    predtr_class = []\n",
    "    predtest_class = []\n",
    "\n",
    "    Y_tr2 = keras.utils.to_categorical(Y_tr)\n",
    "    Y_val2 = keras.utils.to_categorical(Y_val)\n",
    "\n",
    "    ##BRIER SKILL SCORE\n",
    "    BSS_all[l] = BSS(Y_all,pred2)\n",
    "    BSS_val[l] = BSS(Y_val2,pred_val2)\n",
    "    BSS_train[l] = BSS(Y_tr2,pred_train2)\n",
    "    BSS_test[l] = BSS(Y_tes,pred_test2) \n",
    "    \n",
    "    ##RECALL ACCURACY SCORE    \n",
    "    RAS(l, Rec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Rec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Rec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Rec_test, Y_tes, pred_test2, predtest_class)\n",
    "    ##PRECISION ACCURACY SCORE     \n",
    "    PAS(l, Prec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Prec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Prec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Prec_test, Y_tes, pred_test2, predtest_class)\n",
    "    \n",
    "    #___________________________Higher confidence samples_______________________\n",
    "\n",
    "    q90 = np.percentile(pred_test2,90,axis=0) ##90th percentile of test\n",
    "    ##90th percentile acc\n",
    "    great90 = [i for i, row in enumerate(pred_test2) if (row[0] > q90[0]) or (row[1] > q90[1])]\n",
    "    # Create the arrays of probabilities and actual values that exceed the 90th percentile\n",
    "    test90 = pred_test2[great90]\n",
    "    test90_norm = Y_tes[great90]\n",
    "    test90_acc.append(calculate_accuracy(test90_norm, test90, threshold=0.5))\n",
    "    ##full model\n",
    "    fulltest_acc.append(calculate_accuracy(Y_tes, pred_test2, threshold=0.5))\n",
    "\n",
    "    ##classify the accuracy of predicitons\n",
    "    correct_pos = [] #correct positive anomaly\n",
    "    correct_neg = [] #correct negative anomaly\n",
    "    \n",
    "    false_pos = [] #false positive\n",
    "    false_neg = [] #false negative\n",
    "\n",
    "    indexes.extend(great90)\n",
    "    for j in range(len(great90)):\n",
    "        #print(j)\n",
    "        #print(great90[j])\n",
    "        index = great90[j]\n",
    "        if pred_test2[index,0] < pred_test2[index,1] and Y_tes[index,0] == 0:\n",
    "            correct_pos.append(index)\n",
    "            #print('###########')\n",
    "        elif pred_test2[index,0] > pred_test2[index,1] and Y_tes[index,0] == 1:\n",
    "            correct_neg.append(index)\n",
    "            #print('###########')\n",
    "        elif pred_test2[index,0] < pred_test2[index,1] and Y_tes[index,0] == 1:\n",
    "            false_neg.append(index)\n",
    "            #print('###########')\n",
    "        elif pred_test2[index,0] > pred_test2[index,1] and Y_tes[index,0] == 0:\n",
    "            false_pos.append(index)\n",
    "            #print('###########')\n",
    "\n",
    "    ##correct positive\n",
    "    posXtest.extend(correct_pos)\n",
    "    #false positive\n",
    "    FposXtest.extend(false_pos)\n",
    "    #correct negative\n",
    "    negXtest.extend(correct_neg)\n",
    "    #false negative\n",
    "    FnegXtest.extend(false_neg)\n",
    "    \n",
    "    percpos.append(len(correct_pos)/len(great90))\n",
    "    #false positive\n",
    "    percFpos.append(len(false_pos)/len(great90))\n",
    "    #correct negative\n",
    "    percneg.append(len(correct_neg)/len(great90))\n",
    "    #false negative\n",
    "    percFneg.append(len(false_neg)/len(great90))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d70e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('###################################################')\n",
    "print(f'Accuracy, Validation: {np.mean(acc_reg2_val) * 100:.2f}%')\n",
    "print(f'Accuracy, Training: {np.mean(acc_reg2_train) * 100:.2f}%')\n",
    "print(f'Accuracy, Testing: {np.mean(acc_reg2_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "font = 16\n",
    "#loop through each member\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ticks = ['Full', 'Train', 'Val', 'Test'] #set tick numbers for dataset\n",
    "colors = ['lightcyan','indianred']\n",
    "ind = [2, 4, 6, 8]  # the x locations for the groups\n",
    "w = 0.3 #box-plot width\n",
    "labels = ['- Anom', '+ Anom '] #labels of quantiles\n",
    "\n",
    "\n",
    "##begin to go plot by plot ...\n",
    "#each plot has a separate plot function for each lead time. In these, the plots get each quantile plotted. \n",
    "plt.suptitle(\"Stat Scores for Predicting Sign of Europe Temp Anoms in Reduced RF Model at 14-days Leadtime\",fontsize = 18) \n",
    "\n",
    "a1_0 = ax1.boxplot(BSS_all[:], positions= [2], widths=w, patch_artist=True)\n",
    "a1_5 = ax1.boxplot(BSS_train[:], positions=[4], widths=w, patch_artist=True)\n",
    "a1_10 = ax1.boxplot(BSS_val[:], positions=[6], widths=w, patch_artist=True)\n",
    "a1_14 = ax1.boxplot(BSS_test[:], positions=[7], widths=w, patch_artist=True)\n",
    "ax1.axhline(0, c='k', ls ='-.')\n",
    "ax1.set_xticks(ind, ticks)\n",
    "#next few lines color the box plot faces\n",
    "for bplot in (a1_0, a1_5, a1_10, a1_14,):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "#for patch, label in zip(a1_0['boxes'], labels):\n",
    "    #patch.set_label(label)\n",
    "ax1.set_title('BSS for Temperature Region',fontsize = 14)\n",
    "ax1.set_ylim(-0.1,0.25)\n",
    "ax1.set_xlabel('Data Set',fontsize = 14)\n",
    "ax1.set_ylabel('BSS',fontsize = font)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax1.legend(loc = 'lower right', fontsize = 10)\n",
    "ax1.set_aspect('auto') ;\n",
    "\n",
    "##repeat the process\n",
    "a2_0 = ax2.boxplot([Rec_all[:,0],Rec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a2_5 = ax2.boxplot([Rec_train[:,0],Rec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a2_10 = ax2.boxplot([Rec_val[:,0],Rec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a2_14 = ax2.boxplot([Rec_test[:,0],Rec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax2.axhline(0.5, c='k', ls ='-.')\n",
    "ax2.set_xticks(ind, ticks)\n",
    "for bplot in (a2_0, a2_5, a2_10, a2_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a2_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax2.set_title('RAS for Temperature Region',fontsize = 14)\n",
    "ax2.set_ylim(-0.1,1.1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax2.set_ylabel('RAS',fontsize = font)\n",
    "#ax2.set_xlabel('Data Set',fontsize = 14)\n",
    "#ax2.set_ylabel('Brier Skill Score')\n",
    "ax2.legend(loc = 'lower right', fontsize = 14)\n",
    "ax2.set_aspect('auto') ;\n",
    "\n",
    "a3_0 = ax3.boxplot([Prec_all[:,0],Prec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a3_5 = ax3.boxplot([Prec_train[:,0],Prec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a3_10 = ax3.boxplot([Prec_val[:,0],Prec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a3_14 = ax3.boxplot([Prec_test[:,0],Prec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax3.axhline(0.5, c='k', ls ='-.')\n",
    "ax3.set_xticks(ind, ticks)\n",
    "for bplot in (a3_0, a3_5, a3_10, a3_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a3_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax3.set_title('RAS Well')\n",
    "#ax3.set_title('PAS for Temperature Region',fontsize = 14)\n",
    "ax3.set_ylim(-0.1,1.1)\n",
    "ax3.set_ylabel('PAS',fontsize = font)\n",
    "ax3.set_xlabel('Data Set',fontsize = font)\n",
    "#ax3.set_ylabel('Recall Accuracy Score',fontsize = 14)\n",
    "ax3.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax3.legend(loc = 'lower right', fontsize = 14)\n",
    "ax3.set_aspect('auto') ;\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"./images/RedRF_14days_StatScore.png\", bbox_inches='tight',dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a88e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array(p_test)\n",
    "p_test = p_test.reshape((len(p_test)*len(p_test[0]),2))\n",
    "\n",
    "p_train = np.array(p_train)\n",
    "p_train = p_train.reshape((len(p_train)*len(p_train[0]),2))\n",
    "\n",
    "p_val= np.array(p_val)\n",
    "p_val = p_val.reshape((len(p_val)*len(p_val[0]),2))\n",
    "\n",
    "bins = np.linspace(0, 1, 37)  #10 bins from 0.4 to 1\n",
    "fs = 11\n",
    "##bin the probabilities\n",
    "counts_neg_train, edges_neg_train = np.histogram(p_train[:,0], bins=bins)\n",
    "counts_pos_train, edges_pos_train = np.histogram(p_train[:,1], bins=bins)\n",
    "\n",
    "counts_neg_val, edges_neg_val = np.histogram(p_val[:,0], bins=bins)\n",
    "counts_pos_val, edges_pos_val = np.histogram(p_val[:,1], bins=bins)\n",
    "\n",
    "counts_neg_test, edges_neg_test = np.histogram(p_test[:,0], bins=bins)\n",
    "counts_pos_test, edges_pos_test = np.histogram(p_test[:,1], bins=bins)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(11,11))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "\n",
    "ax1.bar(edges_neg_train[:-1], counts_neg_train, width=np.diff(edges_neg_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "ax1.set_title('Negative', fontsize=fs+2)\n",
    "ax1.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "ax1.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax2.bar(edges_pos_train[:-1], counts_pos_train, width=np.diff(edges_pos_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "ax2.set_title('Positive', fontsize=fs+2)\n",
    "ax2.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "#ax2.set_ylabel('Count')\n",
    "\n",
    "ax3.bar(edges_neg_val[:-1], counts_neg_val, width=np.diff(edges_neg_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax3.set_title('Negative Validation Predictions', fontsize=fs)\n",
    "ax3.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "ax3.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax4.bar(edges_pos_val[:-1], counts_pos_val, width=np.diff(edges_pos_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax4.set_title('Positive Validation Predictions', fontsize=fs)\n",
    "ax4.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "#ax4.set_ylabel('Count')\n",
    "\n",
    "ax5.bar(edges_neg_test[:-1], counts_neg_test, width=np.diff(edges_neg_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax5.set_title('Negative Testing Predictions', fontsize=fs)\n",
    "ax5.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "ax5.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax6.bar(edges_pos_test[:-1], counts_pos_test, width=np.diff(edges_pos_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax6.set_title('Positive Testing Predictions', fontsize=fs)\n",
    "ax6.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "#ax6.set_ylabel('Count')\n",
    "\n",
    "plt.suptitle(\"Probability Distributions of Various Datasets Across 100 CVs for Predicting +14 day European Temp Anomalies, RM\", fontsize=fs+4, x=0.525,y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/RF_probdistribRM_14days.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try SHAP with this model\n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rf_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)\n",
    "shap_obj = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9272ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"SHAP Values for Negative Europe Temp Anomalies +14 Days Lead\",fontsize =14, y = 1.05)\n",
    "ax = shap.plots.beeswarm(shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "#ax.set_xlim(-0.3,0.3)  \n",
    "plt.savefig(\"RFshap_Neg_Pred_14days.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9258c003",
   "metadata": {},
   "source": [
    "plt.title(\"SHAP Values for Classifying Positive Temp Anomalies +14 Days Lead\",fontsize =14, y = 1.05)\n",
    "ax = shap.plots.beeswarm(shap_obj[:,:,1], show = False) ##for positive classifications ... this is physically consistent!\n",
    "#ax.set_xlim(-0.2,0.2)\n",
    "#plt.savefig(\"RFshap_Pos_Pred_14days.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######bar plot for showing the distribution of confident predictions\n",
    "bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "##bin the testing 90th percentile accuracy data\n",
    "counts90, edges90 = np.histogram(test90_acc, bins=bins)\n",
    "countsfull, edgesfull = np.histogram(fulltest_acc, bins=bins)\n",
    "# Plot the full dataset\n",
    "#offset = 0.02  # Adjust this value if needed for better visibility\n",
    "plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "        edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "# Plot the 90th percentile\n",
    "plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "        edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "plt.xlabel('Accuracy',fontsize =14)\n",
    "plt.ylabel('Number of Models',fontsize =14)\n",
    "plt.legend()\n",
    "plt.title('Testing Prediction ACC Across 100 RF Models, Europe',fontsize =15)\n",
    "plt.savefig(\"RF_PredACCtest_14days.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d38593",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correct positive\n",
    "posXtest = np.array(posXtest)\n",
    "#false positive\n",
    "FposXtest = np.array(FposXtest)\n",
    "#correct negative\n",
    "negXtest = np.array(negXtest)\n",
    "#false negative\n",
    "FnegXtest = np.array(FnegXtest)\n",
    "\n",
    "indexes = np.array(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53486033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average Num. of 10% Confident and Correct Postive Predictions: {np.mean(percpos)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and Correct Negative Predictions: {np.mean(percneg)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Postive Predictions: {np.mean(percFpos)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Negative Predictions: {np.mean(percFneg)* 100:.2f}%')\n",
    "print('#######################################################################')\n",
    "print(f'Average Num. of 10% Confident and Correct Predictions: {np.mean(percpos)* 100 + np.mean(percneg)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Predictions: {np.mean(percFpos)* 100 +np.mean(percFneg)* 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ba4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####now I wanna make these plots SO ... I am adding an index column on to X_test ... full version. \n",
    "X_test = input.iloc[(57*149):,:]\n",
    "ranges = np.array([x for x in range(0,745,1)])\n",
    "ranges = ranges.reshape(5,149) \n",
    "ranges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a438bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges[0,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##export out files to make the next few plots w/o normalization\n",
    "pickle.dump(ranges, open(\"range_indices_RF14.p\", 'wb'))\n",
    "pickle.dump(posXtest, open(\"posXtest_RF14.p\", 'wb'))\n",
    "pickle.dump(FposXtest, open(\"FposXtest_RF14.p\", 'wb'))\n",
    "pickle.dump(negXtest, open(\"negXtest_RF14.p\", 'wb'))\n",
    "pickle.dump(FnegXtest, open(\"FnegXtest_RF14.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d31706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
