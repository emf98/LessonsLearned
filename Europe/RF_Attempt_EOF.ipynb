{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148bc56d",
   "metadata": {},
   "source": [
    "### Random Forest ... but make it with the EOFs because I can lol. \n",
    "\n",
    "7/23/2025"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b6c98ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ada17ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#relevant import statements\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374c142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##just to stop the excess number of warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa87b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import definitions from skill stat file\n",
    "from SkillStats_MOD import BSS\n",
    "from SkillStats_MOD import RAS\n",
    "from SkillStats_MOD import PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d9329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 135\n",
    "#switch to 149 for normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3f0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 14\n",
    "#0 if normal\n",
    "#this indicates setting the start date as November 2 rather than October 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4576ece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 135, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load input data\n",
    "infile = open(\"../../REAL/reduced_data/PCs/U_14.p\",\"rb\",)\n",
    "U_PC = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "U_PC = U_PC.reshape(62,149,10)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../REAL/reduced_data/PCs/EHF_14.p\",\"rb\",)\n",
    "EHF_PC = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "EHF_PC = EHF_PC.reshape(62,149,45)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../REAL/reduced_data/PCs/GPH_14.p\",\"rb\",)\n",
    "GPH_PC = pickle.load(infile)  \n",
    "GPH_PC = GPH_PC.reshape(62,149,10)\n",
    "infile.close()\n",
    "\n",
    "##remove PC 1\n",
    "U_PC = U_PC[:, shift:, 1:]\n",
    "EHF_PC = EHF_PC[:, shift:, 1:]\n",
    "GPH_PC = GPH_PC[:, shift:, 1:]\n",
    "\n",
    "U_PC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cc0d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U3</th>\n",
       "      <th>GPH4</th>\n",
       "      <th>U2</th>\n",
       "      <th>GPH2</th>\n",
       "      <th>EHF2</th>\n",
       "      <th>GPH5</th>\n",
       "      <th>U4</th>\n",
       "      <th>EHF24</th>\n",
       "      <th>EHF19</th>\n",
       "      <th>EHF7</th>\n",
       "      <th>EHF13</th>\n",
       "      <th>U8</th>\n",
       "      <th>EHF4</th>\n",
       "      <th>EHF31</th>\n",
       "      <th>EHF14</th>\n",
       "      <th>EHF11</th>\n",
       "      <th>EHF8</th>\n",
       "      <th>EHF15</th>\n",
       "      <th>EHF5</th>\n",
       "      <th>EHF6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.186052</td>\n",
       "      <td>1.401645</td>\n",
       "      <td>0.752621</td>\n",
       "      <td>0.209807</td>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.333147</td>\n",
       "      <td>-1.238869</td>\n",
       "      <td>-0.566598</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>0.114243</td>\n",
       "      <td>0.467725</td>\n",
       "      <td>-0.196677</td>\n",
       "      <td>-0.048604</td>\n",
       "      <td>-1.407014</td>\n",
       "      <td>-0.003502</td>\n",
       "      <td>-0.144331</td>\n",
       "      <td>0.169488</td>\n",
       "      <td>-0.005603</td>\n",
       "      <td>0.307784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.252295</td>\n",
       "      <td>1.508203</td>\n",
       "      <td>0.767788</td>\n",
       "      <td>0.393342</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>-0.175079</td>\n",
       "      <td>0.054316</td>\n",
       "      <td>-1.555307</td>\n",
       "      <td>-1.015816</td>\n",
       "      <td>0.402462</td>\n",
       "      <td>-1.206520</td>\n",
       "      <td>0.411638</td>\n",
       "      <td>-0.122714</td>\n",
       "      <td>-0.316326</td>\n",
       "      <td>-1.194313</td>\n",
       "      <td>0.396331</td>\n",
       "      <td>-0.113486</td>\n",
       "      <td>-0.119404</td>\n",
       "      <td>0.095775</td>\n",
       "      <td>0.173497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.341869</td>\n",
       "      <td>1.354320</td>\n",
       "      <td>0.850664</td>\n",
       "      <td>0.672118</td>\n",
       "      <td>0.052752</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>-0.086885</td>\n",
       "      <td>0.100384</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.367632</td>\n",
       "      <td>-1.009713</td>\n",
       "      <td>0.588128</td>\n",
       "      <td>-0.130009</td>\n",
       "      <td>0.284854</td>\n",
       "      <td>0.358146</td>\n",
       "      <td>-0.365585</td>\n",
       "      <td>-0.240902</td>\n",
       "      <td>-0.346428</td>\n",
       "      <td>0.181739</td>\n",
       "      <td>0.142555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.400461</td>\n",
       "      <td>1.396061</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.783787</td>\n",
       "      <td>0.153233</td>\n",
       "      <td>0.056179</td>\n",
       "      <td>-0.210343</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.370710</td>\n",
       "      <td>0.425922</td>\n",
       "      <td>0.284332</td>\n",
       "      <td>0.725755</td>\n",
       "      <td>-0.064082</td>\n",
       "      <td>0.098467</td>\n",
       "      <td>0.163162</td>\n",
       "      <td>-0.705649</td>\n",
       "      <td>-0.415141</td>\n",
       "      <td>0.130562</td>\n",
       "      <td>0.279532</td>\n",
       "      <td>0.223443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.462145</td>\n",
       "      <td>1.371293</td>\n",
       "      <td>0.738818</td>\n",
       "      <td>0.786336</td>\n",
       "      <td>0.215701</td>\n",
       "      <td>0.308007</td>\n",
       "      <td>-0.268501</td>\n",
       "      <td>0.696554</td>\n",
       "      <td>-0.047688</td>\n",
       "      <td>0.279267</td>\n",
       "      <td>0.409636</td>\n",
       "      <td>1.239921</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.190916</td>\n",
       "      <td>-0.208728</td>\n",
       "      <td>-0.345254</td>\n",
       "      <td>-0.518787</td>\n",
       "      <td>0.394408</td>\n",
       "      <td>0.322096</td>\n",
       "      <td>0.105504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>0.344881</td>\n",
       "      <td>-0.931433</td>\n",
       "      <td>0.739117</td>\n",
       "      <td>1.871430</td>\n",
       "      <td>-0.032577</td>\n",
       "      <td>-0.594206</td>\n",
       "      <td>-1.039941</td>\n",
       "      <td>-0.509073</td>\n",
       "      <td>-0.257606</td>\n",
       "      <td>-0.355304</td>\n",
       "      <td>-0.337902</td>\n",
       "      <td>1.955351</td>\n",
       "      <td>0.696732</td>\n",
       "      <td>-0.993664</td>\n",
       "      <td>-0.459643</td>\n",
       "      <td>-0.780476</td>\n",
       "      <td>0.085641</td>\n",
       "      <td>0.103523</td>\n",
       "      <td>1.020420</td>\n",
       "      <td>-0.827579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>0.610486</td>\n",
       "      <td>-0.883960</td>\n",
       "      <td>0.708051</td>\n",
       "      <td>1.945315</td>\n",
       "      <td>0.100459</td>\n",
       "      <td>-0.255287</td>\n",
       "      <td>-0.735913</td>\n",
       "      <td>-0.484002</td>\n",
       "      <td>0.104951</td>\n",
       "      <td>-0.734529</td>\n",
       "      <td>-0.387806</td>\n",
       "      <td>2.091698</td>\n",
       "      <td>0.528793</td>\n",
       "      <td>-0.712909</td>\n",
       "      <td>0.187002</td>\n",
       "      <td>-0.496463</td>\n",
       "      <td>-0.079321</td>\n",
       "      <td>0.201060</td>\n",
       "      <td>0.726277</td>\n",
       "      <td>-0.338853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8367</th>\n",
       "      <td>0.813433</td>\n",
       "      <td>-1.013030</td>\n",
       "      <td>0.612392</td>\n",
       "      <td>1.904598</td>\n",
       "      <td>0.138989</td>\n",
       "      <td>-0.031661</td>\n",
       "      <td>-0.491388</td>\n",
       "      <td>-0.967253</td>\n",
       "      <td>-0.227728</td>\n",
       "      <td>-0.252240</td>\n",
       "      <td>-0.915382</td>\n",
       "      <td>2.458308</td>\n",
       "      <td>0.276310</td>\n",
       "      <td>0.378725</td>\n",
       "      <td>0.115268</td>\n",
       "      <td>-0.112195</td>\n",
       "      <td>0.129463</td>\n",
       "      <td>-0.507578</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.129632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8368</th>\n",
       "      <td>0.300776</td>\n",
       "      <td>-1.099654</td>\n",
       "      <td>0.179745</td>\n",
       "      <td>1.709359</td>\n",
       "      <td>0.101430</td>\n",
       "      <td>-0.021087</td>\n",
       "      <td>-0.592462</td>\n",
       "      <td>-1.556661</td>\n",
       "      <td>-0.148204</td>\n",
       "      <td>0.084979</td>\n",
       "      <td>-2.017825</td>\n",
       "      <td>1.450899</td>\n",
       "      <td>0.127205</td>\n",
       "      <td>0.196277</td>\n",
       "      <td>0.509032</td>\n",
       "      <td>0.827147</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>-0.492190</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.058502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8369</th>\n",
       "      <td>-0.141076</td>\n",
       "      <td>-0.841747</td>\n",
       "      <td>-0.171662</td>\n",
       "      <td>1.518323</td>\n",
       "      <td>0.178951</td>\n",
       "      <td>-0.354376</td>\n",
       "      <td>-0.920245</td>\n",
       "      <td>-0.362053</td>\n",
       "      <td>0.017998</td>\n",
       "      <td>-0.229013</td>\n",
       "      <td>-2.150286</td>\n",
       "      <td>0.644020</td>\n",
       "      <td>0.027940</td>\n",
       "      <td>0.382890</td>\n",
       "      <td>1.099226</td>\n",
       "      <td>0.677530</td>\n",
       "      <td>-0.054276</td>\n",
       "      <td>-0.581448</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>-0.055451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8370 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            U3      GPH4        U2      GPH2      EHF2      GPH5        U4  \\\n",
       "0    -1.186052  1.401645  0.752621  0.209807  0.027478  0.018301  0.333147   \n",
       "1    -1.252295  1.508203  0.767788  0.393342  0.026738 -0.175079  0.054316   \n",
       "2    -1.341869  1.354320  0.850664  0.672118  0.052752 -0.119300 -0.086885   \n",
       "3    -1.400461  1.396061  0.814725  0.783787  0.153233  0.056179 -0.210343   \n",
       "4    -1.462145  1.371293  0.738818  0.786336  0.215701  0.308007 -0.268501   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8365  0.344881 -0.931433  0.739117  1.871430 -0.032577 -0.594206 -1.039941   \n",
       "8366  0.610486 -0.883960  0.708051  1.945315  0.100459 -0.255287 -0.735913   \n",
       "8367  0.813433 -1.013030  0.612392  1.904598  0.138989 -0.031661 -0.491388   \n",
       "8368  0.300776 -1.099654  0.179745  1.709359  0.101430 -0.021087 -0.592462   \n",
       "8369 -0.141076 -0.841747 -0.171662  1.518323  0.178951 -0.354376 -0.920245   \n",
       "\n",
       "         EHF24     EHF19      EHF7     EHF13        U8      EHF4     EHF31  \\\n",
       "0    -1.238869 -0.566598  0.375148  0.114243  0.467725 -0.196677 -0.048604   \n",
       "1    -1.555307 -1.015816  0.402462 -1.206520  0.411638 -0.122714 -0.316326   \n",
       "2     0.100384  0.062058  0.367632 -1.009713  0.588128 -0.130009  0.284854   \n",
       "3     0.446200  0.370710  0.425922  0.284332  0.725755 -0.064082  0.098467   \n",
       "4     0.696554 -0.047688  0.279267  0.409636  1.239921  0.012594  0.190916   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8365 -0.509073 -0.257606 -0.355304 -0.337902  1.955351  0.696732 -0.993664   \n",
       "8366 -0.484002  0.104951 -0.734529 -0.387806  2.091698  0.528793 -0.712909   \n",
       "8367 -0.967253 -0.227728 -0.252240 -0.915382  2.458308  0.276310  0.378725   \n",
       "8368 -1.556661 -0.148204  0.084979 -2.017825  1.450899  0.127205  0.196277   \n",
       "8369 -0.362053  0.017998 -0.229013 -2.150286  0.644020  0.027940  0.382890   \n",
       "\n",
       "         EHF14     EHF11      EHF8     EHF15      EHF5      EHF6  \n",
       "0    -1.407014 -0.003502 -0.144331  0.169488 -0.005603  0.307784  \n",
       "1    -1.194313  0.396331 -0.113486 -0.119404  0.095775  0.173497  \n",
       "2     0.358146 -0.365585 -0.240902 -0.346428  0.181739  0.142555  \n",
       "3     0.163162 -0.705649 -0.415141  0.130562  0.279532  0.223443  \n",
       "4    -0.208728 -0.345254 -0.518787  0.394408  0.322096  0.105504  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "8365 -0.459643 -0.780476  0.085641  0.103523  1.020420 -0.827579  \n",
       "8366  0.187002 -0.496463 -0.079321  0.201060  0.726277 -0.338853  \n",
       "8367  0.115268 -0.112195  0.129463 -0.507578  0.114448  0.129632  \n",
       "8368  0.509032  0.827147  0.147253 -0.492190  0.008271  0.058502  \n",
       "8369  1.099226  0.677530 -0.054276 -0.581448  0.019743 -0.055451  \n",
       "\n",
       "[8370 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create one array of PCs\n",
    "inputvar = np.concatenate((U_PC,EHF_PC,GPH_PC),axis=2) \n",
    "inp1 = inputvar.reshape((62*idx),62)\n",
    "\n",
    "##make pandas dataframe for RF\n",
    "inp = pd.DataFrame(inp1)\n",
    "\n",
    "#create pd datafram of selected feature columns.\n",
    "inp = inp[[1, 56, 0, 54, 9, 57, 2, 31, 26, 14, 20, 6, 11, 38, 21, 18, 15, 22, 12, 13]]\n",
    "#label columns of variables for input data\n",
    "col_names = ['U3', 'GPH4', 'U2', 'GPH2', 'EHF2', 'GPH5', 'U4', 'EHF24', 'EHF19', 'EHF7',\n",
    "            'EHF13', 'U8', 'EHF4', 'EHF31', 'EHF14', 'EHF11', 'EHF8', 'EHF15', 'EHF5', 'EHF6']\n",
    "\n",
    "inp.columns = col_names\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e32b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load output data file.\n",
    "#I can change this to represent any of the available temp regions. \n",
    "infile = open(\"../data/eur_anomtemps_reduced.p\",\"rb\",)\n",
    "temp = pickle.load(infile) \n",
    "infile.close()\n",
    "\n",
    "# load climo data\n",
    "infile = open(\"../data/eur_climoprob_reduced.p\",\"rb\",)\n",
    "climo = pickle.load(infile) \n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84cfd546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9238,)\n",
      "(9238, 2)\n"
     ]
    }
   ],
   "source": [
    "print(temp.shape)\n",
    "print(climo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f01c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.reshape(62,149) ##it was flattened, reshape it\n",
    "climo = climo.reshape(62,149,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74929e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8370,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##reshape again to introduce lag. \n",
    "output = temp[:,shift:].reshape(62*idx)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbde31ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8370, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##reshaping climo\n",
    "climo = climo[:,shift:,:].reshape(62*idx,2)\n",
    "climo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ffa3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032daba3",
   "metadata": {},
   "source": [
    "### Start Random Forest Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc9aab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first ... split data into training/testing ...\n",
    "##this is just taking the first 58 years of data, leaving the remaining 5 for testing\n",
    "X_train = inp.iloc[:(52*idx),:]\n",
    "X_test = inp.iloc[(52*idx):,:]\n",
    "Y_train = output[:(52*idx)]\n",
    "Y_test = output[(52*idx):]\n",
    "\n",
    "val_subset = (10*idx) #index for subsetting validation data in cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80cfeb94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U3</th>\n",
       "      <th>GPH4</th>\n",
       "      <th>U2</th>\n",
       "      <th>GPH2</th>\n",
       "      <th>EHF2</th>\n",
       "      <th>GPH5</th>\n",
       "      <th>U4</th>\n",
       "      <th>EHF24</th>\n",
       "      <th>EHF19</th>\n",
       "      <th>EHF7</th>\n",
       "      <th>EHF13</th>\n",
       "      <th>U8</th>\n",
       "      <th>EHF4</th>\n",
       "      <th>EHF31</th>\n",
       "      <th>EHF14</th>\n",
       "      <th>EHF11</th>\n",
       "      <th>EHF8</th>\n",
       "      <th>EHF15</th>\n",
       "      <th>EHF5</th>\n",
       "      <th>EHF6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.136890</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.043395</td>\n",
       "      <td>-0.047829</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>-0.065971</td>\n",
       "      <td>-0.107266</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>-0.015183</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>-0.014003</td>\n",
       "      <td>-0.087908</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>-0.016633</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>-0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.915184</td>\n",
       "      <td>0.898599</td>\n",
       "      <td>1.042217</td>\n",
       "      <td>1.016813</td>\n",
       "      <td>1.024621</td>\n",
       "      <td>1.015980</td>\n",
       "      <td>0.973055</td>\n",
       "      <td>1.025215</td>\n",
       "      <td>1.028606</td>\n",
       "      <td>1.036236</td>\n",
       "      <td>1.021454</td>\n",
       "      <td>0.971420</td>\n",
       "      <td>1.016370</td>\n",
       "      <td>1.024832</td>\n",
       "      <td>1.029836</td>\n",
       "      <td>1.023088</td>\n",
       "      <td>1.025133</td>\n",
       "      <td>1.018889</td>\n",
       "      <td>1.000869</td>\n",
       "      <td>1.033261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.330901</td>\n",
       "      <td>-3.385422</td>\n",
       "      <td>-3.722318</td>\n",
       "      <td>-3.453941</td>\n",
       "      <td>-5.644896</td>\n",
       "      <td>-4.587965</td>\n",
       "      <td>-3.277297</td>\n",
       "      <td>-4.416084</td>\n",
       "      <td>-7.250258</td>\n",
       "      <td>-4.508757</td>\n",
       "      <td>-5.269061</td>\n",
       "      <td>-3.519752</td>\n",
       "      <td>-9.590916</td>\n",
       "      <td>-7.026523</td>\n",
       "      <td>-5.584905</td>\n",
       "      <td>-7.551976</td>\n",
       "      <td>-9.831314</td>\n",
       "      <td>-5.088114</td>\n",
       "      <td>-6.483733</td>\n",
       "      <td>-6.048667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.538224</td>\n",
       "      <td>-0.757411</td>\n",
       "      <td>-0.828523</td>\n",
       "      <td>-0.716830</td>\n",
       "      <td>-0.471251</td>\n",
       "      <td>-0.687391</td>\n",
       "      <td>-0.789768</td>\n",
       "      <td>-0.589327</td>\n",
       "      <td>-0.539445</td>\n",
       "      <td>-0.487114</td>\n",
       "      <td>-0.594844</td>\n",
       "      <td>-0.759829</td>\n",
       "      <td>-0.415736</td>\n",
       "      <td>-0.466632</td>\n",
       "      <td>-0.609614</td>\n",
       "      <td>-0.532590</td>\n",
       "      <td>-0.392148</td>\n",
       "      <td>-0.564217</td>\n",
       "      <td>-0.430135</td>\n",
       "      <td>-0.510797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.156188</td>\n",
       "      <td>-0.158145</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>-0.044677</td>\n",
       "      <td>-0.087615</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.006759</td>\n",
       "      <td>-0.050709</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>-0.089450</td>\n",
       "      <td>0.034990</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>-0.012936</td>\n",
       "      <td>-0.006851</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>-0.059391</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.031766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.472534</td>\n",
       "      <td>0.752504</td>\n",
       "      <td>0.641659</td>\n",
       "      <td>0.388984</td>\n",
       "      <td>0.576937</td>\n",
       "      <td>0.566832</td>\n",
       "      <td>0.594545</td>\n",
       "      <td>0.548304</td>\n",
       "      <td>0.373760</td>\n",
       "      <td>0.606279</td>\n",
       "      <td>0.557022</td>\n",
       "      <td>0.471302</td>\n",
       "      <td>0.478167</td>\n",
       "      <td>0.628288</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.430484</td>\n",
       "      <td>0.459110</td>\n",
       "      <td>0.436346</td>\n",
       "      <td>0.458258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.336169</td>\n",
       "      <td>2.464505</td>\n",
       "      <td>3.271427</td>\n",
       "      <td>3.099698</td>\n",
       "      <td>5.523659</td>\n",
       "      <td>3.512782</td>\n",
       "      <td>3.169371</td>\n",
       "      <td>5.693684</td>\n",
       "      <td>5.225410</td>\n",
       "      <td>9.546534</td>\n",
       "      <td>4.214322</td>\n",
       "      <td>3.705687</td>\n",
       "      <td>5.137964</td>\n",
       "      <td>8.432438</td>\n",
       "      <td>5.055216</td>\n",
       "      <td>5.431998</td>\n",
       "      <td>6.726635</td>\n",
       "      <td>5.261486</td>\n",
       "      <td>7.119503</td>\n",
       "      <td>6.085674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                U3         GPH4           U2         GPH2         EHF2  \\\n",
       "count  7020.000000  7020.000000  7020.000000  7020.000000  7020.000000   \n",
       "mean      0.136890    -0.155964    -0.043395    -0.047829     0.002735   \n",
       "std       0.915184     0.898599     1.042217     1.016813     1.024621   \n",
       "min      -2.330901    -3.385422    -3.722318    -3.453941    -5.644896   \n",
       "25%      -0.538224    -0.757411    -0.828523    -0.716830    -0.471251   \n",
       "50%       0.156188    -0.158145     0.005295     0.001731    -0.001661   \n",
       "75%       0.784997     0.472534     0.752504     0.641659     0.388984   \n",
       "max       3.336169     2.464505     3.271427     3.099698     5.523659   \n",
       "\n",
       "              GPH5           U4        EHF24        EHF19         EHF7  \\\n",
       "count  7020.000000  7020.000000  7020.000000  7020.000000  7020.000000   \n",
       "mean     -0.065971    -0.107266     0.001246    -0.015183     0.006561   \n",
       "std       1.015980     0.973055     1.025215     1.028606     1.036236   \n",
       "min      -4.587965    -3.277297    -4.416084    -7.250258    -4.508757   \n",
       "25%      -0.687391    -0.789768    -0.589327    -0.539445    -0.487114   \n",
       "50%      -0.044677    -0.087615     0.000429    -0.006759    -0.050709   \n",
       "75%       0.576937     0.566832     0.594545     0.548304     0.373760   \n",
       "max       3.512782     3.169371     5.693684     5.225410     9.546534   \n",
       "\n",
       "             EHF13           U8         EHF4        EHF31        EHF14  \\\n",
       "count  7020.000000  7020.000000  7020.000000  7020.000000  7020.000000   \n",
       "mean     -0.014003    -0.087908     0.010261    -0.000192     0.019070   \n",
       "std       1.021454     0.971420     1.016370     1.024832     1.029836   \n",
       "min      -5.269061    -3.519752    -9.590916    -7.026523    -5.584905   \n",
       "25%      -0.594844    -0.759829    -0.415736    -0.466632    -0.609614   \n",
       "50%       0.027036    -0.089450     0.034990     0.011031    -0.012936   \n",
       "75%       0.606279     0.557022     0.471302     0.478167     0.628288   \n",
       "max       4.214322     3.705687     5.137964     8.432438     5.055216   \n",
       "\n",
       "             EHF11         EHF8        EHF15         EHF5         EHF6  \n",
       "count  7020.000000  7020.000000  7020.000000  7020.000000  7020.000000  \n",
       "mean      0.030307     0.002022    -0.016633     0.001662    -0.025556  \n",
       "std       1.023088     1.025133     1.018889     1.000869     1.033261  \n",
       "min      -7.551976    -9.831314    -5.088114    -6.483733    -6.048667  \n",
       "25%      -0.532590    -0.392148    -0.564217    -0.430135    -0.510797  \n",
       "50%      -0.006851     0.004418    -0.059391     0.010093     0.031766  \n",
       "75%       0.576849     0.430484     0.459110     0.436346     0.458258  \n",
       "max       5.431998     6.726635     5.261486     7.119503     6.085674  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "792820c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##next are some empty lists, as I love to do lol. \n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36f76209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists to save Accuracy\n",
    "acc_reg1_val = []\n",
    "acc_reg1_train = []\n",
    "acc_reg1_test = []\n",
    "\n",
    "##BSS Arrays, all of the skill scores have 200 rows\n",
    "#because that is how many cross-validations I will do for the model\n",
    "BSS_all= np.empty((n,))\n",
    "BSS_val= np.empty((n,))\n",
    "BSS_train= np.empty((n,))\n",
    "BSS_test= np.empty((n,))\n",
    "\n",
    "##RAS and PAS Arrays\n",
    "Prec_all= np.empty((n,2))\n",
    "Rec_all= np.empty((n,2))\n",
    "\n",
    "Prec_val= np.empty((n,2))\n",
    "Rec_val= np.empty((n,2))\n",
    "\n",
    "Prec_train= np.empty((n,2))\n",
    "Rec_train= np.empty((n,2))\n",
    "\n",
    "Prec_test= np.empty((n,2))\n",
    "Rec_test= np.empty((n,2))\n",
    "\n",
    "important = np.empty((n,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa3d3a57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#save probabilities\n",
    "p_test = []\n",
    "p_train = []\n",
    "p_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b01cfd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create initial regressor for rf to do feature selection \n",
    "rf_reg1 = RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39db0ec",
   "metadata": {},
   "source": [
    "In order for me to add in the appropriate skill scores, since this is a categorical classification, I had to create separate metrics with one hot encoding to calculate BSS/RAS/PAS. \n",
    "\n",
    "I also had to calculate the daily probability for each categorical classification, which is done in the temperature pre-processing file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f140bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 00:04:48.613333: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-24 00:04:48.617298: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-24 00:04:48.667441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-24 00:04:48.667488: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-24 00:04:48.667523: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-24 00:04:48.677742: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-24 00:04:48.678482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "##one-hot encoded outputs for the purpose of calculating probabilities\n",
    "import keras\n",
    "Y_all = keras.utils.to_categorical(output)\n",
    "Y_tes = keras.utils.to_categorical(Y_test)\n",
    "X_all = inp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc5c8ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe28fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val #:0\n",
      "Selected Features: Index(['U3', 'GPH4', 'U2', 'GPH2', 'EHF2'], dtype='object')\n",
      "Cross Val #:1\n",
      "Selected Features: Index(['U3', 'GPH4', 'U2', 'GPH2', 'EHF2'], dtype='object')\n",
      "Cross Val #:2\n"
     ]
    }
   ],
   "source": [
    "##make loop for cross validation \n",
    "for l in range(0,n):\n",
    "    print(\"Cross Val #:\"+str(l))\n",
    "    ##randomly choose a fraction of events for validation and training\n",
    "    start = random.randrange(len(X_train.iloc[:,0])-val_subset)\n",
    "    end = start+(val_subset)\n",
    "\n",
    "    climo_test = climo[(52*idx):,:]\n",
    "    climo_tr = climo[:(52*idx),:]\n",
    "    \n",
    "    X_val = inp.iloc[start:end,:]\n",
    "    Y_val = output[start:end]\n",
    "    climo_val = climo_tr[start:end,:]\n",
    "    \n",
    "    X_train1 = X_train.iloc[0:start]\n",
    "    Y_train1 = Y_train[0:start]\n",
    "    climo_train1 = climo_tr[0:start,:]\n",
    "    X_train2 = X_train.iloc[end:]\n",
    "    Y_train2 = Y_train[end:]\n",
    "    climo_train2 = climo_tr[end:,:]\n",
    "\n",
    "    ##concatenate all of these\n",
    "    X_tr = pd.concat([X_train1,X_train2], axis = 0)\n",
    "    Y_tr = np.concatenate((Y_train1,Y_train2))\n",
    "    climo_train = np.concatenate((climo_train1,climo_train2))\n",
    "    \n",
    "\n",
    "    #_______________________train the model_______________________________\n",
    "    #train rf\n",
    "    rf_reg1.fit(X_tr, Y_tr)\n",
    "    pred1 = rf_reg1.predict(X_all)\n",
    "    pred2 = rf_reg1.predict_proba(X_all)\n",
    "    \n",
    "    #prediction with validation data\n",
    "    pred_val1 = rf_reg1.predict(X_val)\n",
    "    pred_val2 = rf_reg1.predict_proba(X_val)\n",
    "    p_val.append(pred_val2)\n",
    "    acc_reg1_val.append(accuracy_score(Y_val, pred_val1))\n",
    "    \n",
    "    #prediction with training data\n",
    "    pred_train1 = rf_reg1.predict(X_tr)\n",
    "    pred_train2 = rf_reg1.predict_proba(X_tr)\n",
    "    p_train.append(pred_train2)\n",
    "    acc_reg1_train.append(accuracy_score(Y_tr, pred_train1))\n",
    "\n",
    "    #prediction with testing data\n",
    "    pred_test1 = rf_reg1.predict(X_test)\n",
    "    pred_test2 = rf_reg1.predict_proba(X_test)\n",
    "    p_test.append(pred_test2)\n",
    "    acc_reg1_test.append(accuracy_score(Y_test, pred_test1))\n",
    "   \n",
    "    #_______________________feature selection______________________________\n",
    "    #prepare to show relevant features by actually ... choosing them \n",
    "    selector = SelectFromModel(rf_reg1, threshold=\"mean\", max_features=None)\n",
    "    X_train_selected = selector.transform(X_tr)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    #print names of selected features\n",
    "    selected_features = inp.columns[selector.get_support()]\n",
    "    print(f'Selected Features: {selected_features}')\n",
    "\n",
    "    importances = rf_reg1.feature_importances_\n",
    "    important[l,:] = importances[:]\n",
    "    \n",
    "    #_______________________statistics calcs_______________________________\n",
    "    pred_class = []\n",
    "    predval_class = []\n",
    "    predtr_class = []\n",
    "    predtest_class = []\n",
    "    \n",
    "    Y_tr2 = keras.utils.to_categorical(Y_tr)\n",
    "    Y_val2 = keras.utils.to_categorical(Y_val)\n",
    "\n",
    "    ##BRIER SKILL SCORE\n",
    "    BSS_all[l] = BSS(Y_all,pred2)\n",
    "    BSS_val[l] = BSS(Y_val2,pred_val2)\n",
    "    BSS_train[l] = BSS(Y_tr2,pred_train2)\n",
    "    BSS_test[l] = BSS(Y_tes,pred_test2) \n",
    "    \n",
    "    ##RECALL ACCURACY SCORE    \n",
    "    RAS(l, Rec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Rec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Rec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Rec_test, Y_tes, pred_test2, predtest_class)\n",
    "    ##PRECISION ACCURACY SCORE     \n",
    "    PAS(l, Prec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Prec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Prec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Prec_test, Y_tes, pred_test2, predtest_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('###################################################')\n",
    "print(f'Accuracy, Validation: {np.mean(acc_reg1_val) * 100:.2f}%')\n",
    "print(f'Accuracy, Training: {np.mean(acc_reg1_train) * 100:.2f}%')\n",
    "print(f'Accuracy, Testing: {np.mean(acc_reg1_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ce5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "font = 16\n",
    "#loop through each member\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ticks = ['Full', 'Train', 'Val', 'Test'] #set tick numbers for dataset\n",
    "colors = ['lightcyan','indianred']\n",
    "ind = [2, 4, 6, 8]  # the x locations for the groups\n",
    "w = 0.3 #box-plot width\n",
    "labels = ['- Anom', '+ Anom '] #labels of quantiles\n",
    "\n",
    "\n",
    "##begin to go plot by plot ...\n",
    "#each plot has a separate plot function for each lead time. In these, the plots get each quantile plotted. \n",
    "plt.suptitle(\"Stat Scores for Predicting Sign of Europe Temp Anoms in Full EOF RF Model at 14-days Leadtime\",fontsize = 18) \n",
    "\n",
    "a1_0 = ax1.boxplot(BSS_all[:], positions= [2], widths=w, patch_artist=True)\n",
    "a1_5 = ax1.boxplot(BSS_train[:], positions=[4], widths=w, patch_artist=True)\n",
    "a1_10 = ax1.boxplot(BSS_val[:], positions=[6], widths=w, patch_artist=True)\n",
    "a1_14 = ax1.boxplot(BSS_test[:], positions=[7], widths=w, patch_artist=True)\n",
    "ax1.axhline(0, c='k', ls ='-.')\n",
    "ax1.set_xticks(ind, ticks)\n",
    "#next few lines color the box plot faces\n",
    "for bplot in (a1_0, a1_5, a1_10, a1_14,):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "#for patch, label in zip(a1_0['boxes'], labels):\n",
    "    #patch.set_label(label)\n",
    "ax1.set_title('BSS for Temperature Region',fontsize = 14)\n",
    "ax1.set_ylim(-0.1,0.25)\n",
    "ax1.set_xlabel('Data Set',fontsize = 14)\n",
    "ax1.set_ylabel('BSS',fontsize = font)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax1.legend(loc = 'lower right', fontsize = 10)\n",
    "ax1.set_aspect('auto') ;\n",
    "\n",
    "##repeat the process\n",
    "a2_0 = ax2.boxplot([Rec_all[:,0],Rec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a2_5 = ax2.boxplot([Rec_train[:,0],Rec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a2_10 = ax2.boxplot([Rec_val[:,0],Rec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a2_14 = ax2.boxplot([Rec_test[:,0],Rec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax2.axhline(0.5, c='k', ls ='-.')\n",
    "ax2.set_xticks(ind, ticks)\n",
    "for bplot in (a2_0, a2_5, a2_10, a2_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a2_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax2.set_title('RAS for Temperature Region',fontsize = 14)\n",
    "ax2.set_ylim(-0.1,1.1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax2.set_ylabel('RAS',fontsize = font)\n",
    "#ax2.set_xlabel('Data Set',fontsize = 14)\n",
    "#ax2.set_ylabel('Brier Skill Score')\n",
    "ax2.legend(loc = 'lower right', fontsize = 14)\n",
    "ax2.set_aspect('auto') ;\n",
    "\n",
    "a3_0 = ax3.boxplot([Prec_all[:,0],Prec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a3_5 = ax3.boxplot([Prec_train[:,0],Prec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a3_10 = ax3.boxplot([Prec_val[:,0],Prec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a3_14 = ax3.boxplot([Prec_test[:,0],Prec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax3.axhline(0.5, c='k', ls ='-.')\n",
    "ax3.set_xticks(ind, ticks)\n",
    "for bplot in (a3_0, a3_5, a3_10, a3_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a3_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax3.set_title('RAS Well')\n",
    "#ax3.set_title('PAS for Temperature Region',fontsize = 14)\n",
    "ax3.set_ylim(-0.1,1.1)\n",
    "ax3.set_ylabel('PAS',fontsize = font)\n",
    "ax3.set_xlabel('Data Set',fontsize = font)\n",
    "#ax3.set_ylabel('Recall Accuracy Score',fontsize = 14)\n",
    "ax3.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax3.legend(loc = 'lower right', fontsize = 14)\n",
    "ax3.set_aspect('auto') ;\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"./images/FullEOFRF_14days_EurSS.png\", bbox_inches='tight',dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f946528",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array(p_test)\n",
    "p_test = p_test.reshape((len(p_test)*len(p_test[0]),2))\n",
    "\n",
    "p_train = np.array(p_train)\n",
    "p_train = p_train.reshape((len(p_train)*len(p_train[0]),2))\n",
    "\n",
    "p_val= np.array(p_val)\n",
    "p_val = p_val.reshape((len(p_val)*len(p_val[0]),2))\n",
    "\n",
    "bins = np.linspace(0, 1, 37)  #10 bins from 0.4 to 1\n",
    "fs = 11\n",
    "##bin the probabilities\n",
    "counts_neg_train, edges_neg_train = np.histogram(p_train[:,0], bins=bins)\n",
    "counts_pos_train, edges_pos_train = np.histogram(p_train[:,1], bins=bins)\n",
    "\n",
    "counts_neg_val, edges_neg_val = np.histogram(p_val[:,0], bins=bins)\n",
    "counts_pos_val, edges_pos_val = np.histogram(p_val[:,1], bins=bins)\n",
    "\n",
    "counts_neg_test, edges_neg_test = np.histogram(p_test[:,0], bins=bins)\n",
    "counts_pos_test, edges_pos_test = np.histogram(p_test[:,1], bins=bins)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(11,11))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "\n",
    "ax1.bar(edges_neg_train[:-1], counts_neg_train, width=np.diff(edges_neg_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "ax1.set_title('Negative', fontsize=fs+2)\n",
    "ax1.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "ax1.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax2.bar(edges_pos_train[:-1], counts_pos_train, width=np.diff(edges_pos_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "ax2.set_title('Positive', fontsize=fs+2)\n",
    "ax2.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "#ax2.set_ylabel('Count')\n",
    "\n",
    "ax3.bar(edges_neg_val[:-1], counts_neg_val, width=np.diff(edges_neg_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax3.set_title('Negative Validation Predictions', fontsize=fs)\n",
    "ax3.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "ax3.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax4.bar(edges_pos_val[:-1], counts_pos_val, width=np.diff(edges_pos_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax4.set_title('Positive Validation Predictions', fontsize=fs)\n",
    "ax4.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "#ax4.set_ylabel('Count')\n",
    "\n",
    "ax5.bar(edges_neg_test[:-1], counts_neg_test, width=np.diff(edges_neg_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax5.set_title('Negative Testing Predictions', fontsize=fs)\n",
    "ax5.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "ax5.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax6.bar(edges_pos_test[:-1], counts_pos_test, width=np.diff(edges_pos_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax6.set_title('Positive Testing Predictions', fontsize=fs)\n",
    "ax6.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "#ax6.set_ylabel('Count')\n",
    "\n",
    "plt.suptitle(\"Probability Distributions of Various Datasets Across 100 CVs for Predicting +14 day European Temp Anomalies, EOF FM\", fontsize=fs+4, x=0.525,y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/EurEOFRF_probdistrib_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take average across all feature importance values by cross validation\n",
    "imp = np.nanmean(important, axis = 0)\n",
    "imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot features by relative importance\n",
    "indices = np.argsort(imp)[::-1]  #sort by importance\n",
    "c = [\"navy\",\"royalblue\",\"slateblue\",\"blueviolet\",\"darkviolet\",\"purple\",\"mediumvioletred\",\"magenta\"]\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(\"Average Feature Importances Across 100 CVs EOF RF, Europe 14\",fontsize =18)\n",
    "plt.barh(range(inp.shape[1]), imp[indices], align=\"center\", color = c)\n",
    "plt.yticks(range(inp.shape[1]), inp.columns[indices],fontsize =14)\n",
    "plt.xticks(fontsize =14)\n",
    "plt.xlabel(\"Relative Importance\",fontsize =16)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"./images/EurEOFRF_FeatureImportance_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d647a",
   "metadata": {},
   "source": [
    "### Switch over to the reduced model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ea44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##change pandas dataframe to choose top 3 important features only\n",
    "input2 = inp[['U3', \"GPH4\", \"GPH2\",\"U2\",\"EHF2\",\"EHF24\"]]\n",
    "#input2 = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da389646",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#AGAIN, empty lists \n",
    "n = 100\n",
    "#empty lists to save Accuracy\n",
    "acc_reg2_val = []\n",
    "acc_reg2_train = []\n",
    "acc_reg2_test = []\n",
    "\n",
    "##BSS Arrays\n",
    "##BSS Arrays, all of the skill scores have 200 rows\n",
    "#because that is how many cross-validations I will do for the model\n",
    "BSS_all= np.empty((n,))\n",
    "BSS_val= np.empty((n,))\n",
    "BSS_train= np.empty((n,))\n",
    "BSS_test= np.empty((n,))\n",
    "\n",
    "##RAS and PAS Arrays\n",
    "Prec_all= np.empty((n,2))\n",
    "Rec_all= np.empty((n,2))\n",
    "\n",
    "Prec_val= np.empty((n,2))\n",
    "Rec_val= np.empty((n,2))\n",
    "\n",
    "Prec_train= np.empty((n,2))\n",
    "Rec_train= np.empty((n,2))\n",
    "\n",
    "Prec_test= np.empty((n,2))\n",
    "Rec_test= np.empty((n,2))\n",
    "\n",
    "important = np.empty((n,8))\n",
    "\n",
    "#save PREDICTIONS\n",
    "test90_acc = []\n",
    "##full model\n",
    "fulltest_acc = []\n",
    "\n",
    "##correct positive\n",
    "posXtest = []\n",
    "#false positive\n",
    "FposXtest = []\n",
    "#correct negative\n",
    "negXtest = []\n",
    "#false negative\n",
    "FnegXtest = []\n",
    "\n",
    "indexes = []\n",
    "\n",
    "##correct positive\n",
    "percpos = []\n",
    "#false positive\n",
    "percFpos = []\n",
    "#correct negative\n",
    "percneg = []\n",
    "#false negative\n",
    "percFneg = []\n",
    "\n",
    "#save probabilities\n",
    "p_test = []\n",
    "p_train = []\n",
    "p_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first ... split data into training/testing ...\n",
    "##this is just taking the first 58 years of data, leaving the remaining 5 for testing\n",
    "X_train = input2.iloc[:(52*idx),:]\n",
    "X_test = input2.iloc[(52*idx):,:]\n",
    "Y_train = output[:(52*idx)]\n",
    "Y_test = output[(52*idx):]\n",
    "\n",
    "val_subset = (10*idx) #index for subsetting validation data in cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd735f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##definition statement for ACC\n",
    "def calculate_accuracy(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = keras.utils.to_categorical(output)\n",
    "Y_tes = keras.utils.to_categorical(Y_test)\n",
    "X_all = input2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c524ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second random forest model with selected features only\n",
    "rf_reg2 = RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ceb2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make loop for cross validation \n",
    "for l in range(0,n):\n",
    "    print(\"Cross Val #:\"+str(l))\n",
    "    ##randomly choose a fraction of events for validation and training\n",
    "    start = random.randrange(len(X_train.iloc[:,0])-val_subset)\n",
    "    end = start+(val_subset)\n",
    "\n",
    "    climo_test = climo[(52*idx):,:]\n",
    "    climo_tr = climo[:(52*idx),:]\n",
    "    \n",
    "    X_val = input2.iloc[start:end,:]\n",
    "    Y_val = output[start:end]\n",
    "    climo_val = climo_tr[start:end,:]\n",
    "    \n",
    "    X_train1 = X_train.iloc[0:start]\n",
    "    Y_train1 = Y_train[0:start]\n",
    "    climo_train1 = climo_tr[0:start,:]\n",
    "    X_train2 = X_train.iloc[end:]\n",
    "    Y_train2 = Y_train[end:]\n",
    "    climo_train2 = climo_tr[end:,:]\n",
    "\n",
    "    ##concatenate all of these\n",
    "    X_tr = pd.concat([X_train1,X_train2], axis = 0)\n",
    "    Y_tr = np.concatenate((Y_train1,Y_train2))\n",
    "    climo_train = np.concatenate((climo_train1,climo_train2))\n",
    "    \n",
    "    \n",
    "    #_______________________train the model_______________________________\n",
    "    #train rf\n",
    "    rf_reg2.fit(X_tr, Y_tr)\n",
    "    pred1 = rf_reg2.predict(X_all)\n",
    "    pred2 = rf_reg2.predict_proba(X_all)\n",
    "    \n",
    "    #prediction with validation data\n",
    "    pred_val1 = rf_reg2.predict(X_val)\n",
    "    pred_val2 = rf_reg2.predict_proba(X_val)\n",
    "    p_val.append(pred_val2)\n",
    "    acc_reg2_val.append(accuracy_score(Y_val, pred_val1))\n",
    "    \n",
    "    #prediction with training data\n",
    "    pred_train1 = rf_reg2.predict(X_tr)\n",
    "    pred_train2 = rf_reg2.predict_proba(X_tr)\n",
    "    p_train.append(pred_train2)\n",
    "    acc_reg2_train.append(accuracy_score(Y_tr, pred_train1))\n",
    "\n",
    "    #prediction with testing data\n",
    "    pred_test1 = rf_reg2.predict(X_test)\n",
    "    pred_test2 = rf_reg2.predict_proba(X_test)\n",
    "    p_test.append(pred_test2)\n",
    "    acc_reg2_test.append(accuracy_score(Y_test, pred_test1))\n",
    "    \n",
    "    #_______________________statistics calcs_______________________________\n",
    "    pred_class = []\n",
    "    predval_class = []\n",
    "    predtr_class = []\n",
    "    predtest_class = []\n",
    "\n",
    "    Y_tr2 = keras.utils.to_categorical(Y_tr)\n",
    "    Y_val2 = keras.utils.to_categorical(Y_val)\n",
    "\n",
    "    ##BRIER SKILL SCORE\n",
    "    BSS_all[l] = BSS(Y_all,pred2)\n",
    "    BSS_val[l] = BSS(Y_val2,pred_val2)\n",
    "    BSS_train[l] = BSS(Y_tr2,pred_train2)\n",
    "    BSS_test[l] = BSS(Y_tes,pred_test2) \n",
    "    \n",
    "    ##RECALL ACCURACY SCORE    \n",
    "    RAS(l, Rec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Rec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Rec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Rec_test, Y_tes, pred_test2, predtest_class)\n",
    "    ##PRECISION ACCURACY SCORE     \n",
    "    PAS(l, Prec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Prec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Prec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Prec_test, Y_tes, pred_test2, predtest_class)\n",
    "    \n",
    "    #___________________________Higher confidence samples_______________________\n",
    "\n",
    "    q90 = np.percentile(pred_test2,90,axis=0) ##90th percentile of test\n",
    "    ##90th percentile acc\n",
    "    great90 = [i for i, row in enumerate(pred_test2) if (row[0] > q90[0]) or (row[1] > q90[1])]\n",
    "    # Create the arrays of probabilities and actual values that exceed the 90th percentile\n",
    "    test90 = pred_test2[great90]\n",
    "    test90_norm = Y_tes[great90]\n",
    "    test90_acc.append(calculate_accuracy(test90_norm, test90, threshold=0.5))\n",
    "    ##full model\n",
    "    fulltest_acc.append(calculate_accuracy(Y_tes, pred_test2, threshold=0.5))\n",
    "\n",
    "    ##classify the accuracy of predicitons\n",
    "    correct_pos = [] #correct positive anomaly\n",
    "    correct_neg = [] #correct negative anomaly\n",
    "    \n",
    "    false_pos = [] #false positive\n",
    "    false_neg = [] #false negative\n",
    "\n",
    "    indexes.extend(great90)\n",
    "    for j in range(len(great90)):\n",
    "        #print(j)\n",
    "        #print(great90[j])\n",
    "        index = great90[j]\n",
    "        if pred_test2[index,0] < pred_test2[index,1] and Y_tes[index,0] == 0:\n",
    "            correct_pos.append(index)\n",
    "            #print('###########')\n",
    "        elif pred_test2[index,0] > pred_test2[index,1] and Y_tes[index,0] == 1:\n",
    "            correct_neg.append(index)\n",
    "            #print('###########')\n",
    "        elif pred_test2[index,0] < pred_test2[index,1] and Y_tes[index,0] == 1:\n",
    "            false_neg.append(index)\n",
    "            #print('###########')\n",
    "        elif pred_test2[index,0] > pred_test2[index,1] and Y_tes[index,0] == 0:\n",
    "            false_pos.append(index)\n",
    "            #print('###########')\n",
    "\n",
    "    ##correct positive\n",
    "    posXtest.extend(correct_pos)\n",
    "    #false positive\n",
    "    FposXtest.extend(false_pos)\n",
    "    #correct negative\n",
    "    negXtest.extend(correct_neg)\n",
    "    #false negative\n",
    "    FnegXtest.extend(false_neg)\n",
    "    \n",
    "    percpos.append(len(correct_pos)/len(great90))\n",
    "    #false positive\n",
    "    percFpos.append(len(false_pos)/len(great90))\n",
    "    #correct negative\n",
    "    percneg.append(len(correct_neg)/len(great90))\n",
    "    #false negative\n",
    "    percFneg.append(len(false_neg)/len(great90))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('###################################################')\n",
    "print(f'Accuracy, Validation: {np.mean(acc_reg2_val) * 100:.2f}%')\n",
    "print(f'Accuracy, Training: {np.mean(acc_reg2_train) * 100:.2f}%')\n",
    "print(f'Accuracy, Testing: {np.mean(acc_reg2_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "font = 16\n",
    "#loop through each member\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ticks = ['Full', 'Train', 'Val', 'Test'] #set tick numbers for dataset\n",
    "colors = ['lightcyan','indianred']\n",
    "ind = [2, 4, 6, 8]  # the x locations for the groups\n",
    "w = 0.3 #box-plot width\n",
    "labels = ['- Anom', '+ Anom '] #labels of quantiles\n",
    "\n",
    "\n",
    "##begin to go plot by plot ...\n",
    "#each plot has a separate plot function for each lead time. In these, the plots get each quantile plotted. \n",
    "plt.suptitle(\"Stat Scores for Predicting Sign of Europe Temp Anoms in Reduced EOF RF Model at 14-days Leadtime\",fontsize = 18) \n",
    "\n",
    "a1_0 = ax1.boxplot(BSS_all[:], positions= [2], widths=w, patch_artist=True)\n",
    "a1_5 = ax1.boxplot(BSS_train[:], positions=[4], widths=w, patch_artist=True)\n",
    "a1_10 = ax1.boxplot(BSS_val[:], positions=[6], widths=w, patch_artist=True)\n",
    "a1_14 = ax1.boxplot(BSS_test[:], positions=[7], widths=w, patch_artist=True)\n",
    "ax1.axhline(0, c='k', ls ='-.')\n",
    "ax1.set_xticks(ind, ticks)\n",
    "#next few lines color the box plot faces\n",
    "for bplot in (a1_0, a1_5, a1_10, a1_14,):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "#for patch, label in zip(a1_0['boxes'], labels):\n",
    "    #patch.set_label(label)\n",
    "ax1.set_title('BSS for Temperature Region',fontsize = 14)\n",
    "ax1.set_ylim(-0.1,0.25)\n",
    "ax1.set_xlabel('Data Set',fontsize = 14)\n",
    "ax1.set_ylabel('BSS',fontsize = font)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax1.legend(loc = 'lower right', fontsize = 10)\n",
    "ax1.set_aspect('auto') ;\n",
    "\n",
    "##repeat the process\n",
    "a2_0 = ax2.boxplot([Rec_all[:,0],Rec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a2_5 = ax2.boxplot([Rec_train[:,0],Rec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a2_10 = ax2.boxplot([Rec_val[:,0],Rec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a2_14 = ax2.boxplot([Rec_test[:,0],Rec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax2.axhline(0.5, c='k', ls ='-.')\n",
    "ax2.set_xticks(ind, ticks)\n",
    "for bplot in (a2_0, a2_5, a2_10, a2_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a2_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax2.set_title('RAS for Temperature Region',fontsize = 14)\n",
    "ax2.set_ylim(-0.1,1.1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax2.set_ylabel('RAS',fontsize = font)\n",
    "#ax2.set_xlabel('Data Set',fontsize = 14)\n",
    "#ax2.set_ylabel('Brier Skill Score')\n",
    "ax2.legend(loc = 'lower right', fontsize = 14)\n",
    "ax2.set_aspect('auto') ;\n",
    "\n",
    "a3_0 = ax3.boxplot([Prec_all[:,0],Prec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a3_5 = ax3.boxplot([Prec_train[:,0],Prec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a3_10 = ax3.boxplot([Prec_val[:,0],Prec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a3_14 = ax3.boxplot([Prec_test[:,0],Prec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax3.axhline(0.5, c='k', ls ='-.')\n",
    "ax3.set_xticks(ind, ticks)\n",
    "for bplot in (a3_0, a3_5, a3_10, a3_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a3_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax3.set_title('RAS Well')\n",
    "#ax3.set_title('PAS for Temperature Region',fontsize = 14)\n",
    "ax3.set_ylim(-0.1,1.1)\n",
    "ax3.set_ylabel('PAS',fontsize = font)\n",
    "ax3.set_xlabel('Data Set',fontsize = font)\n",
    "#ax3.set_ylabel('Recall Accuracy Score',fontsize = 14)\n",
    "ax3.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax3.legend(loc = 'lower right', fontsize = 14)\n",
    "ax3.set_aspect('auto') ;\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"./images/RedEOFRF_14days_EurSS.png\", bbox_inches='tight',dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array(p_test)\n",
    "p_test = p_test.reshape((len(p_test)*len(p_test[0]),2))\n",
    "\n",
    "p_train = np.array(p_train)\n",
    "p_train = p_train.reshape((len(p_train)*len(p_train[0]),2))\n",
    "\n",
    "p_val= np.array(p_val)\n",
    "p_val = p_val.reshape((len(p_val)*len(p_val[0]),2))\n",
    "\n",
    "bins = np.linspace(0, 1, 37)  #10 bins from 0.4 to 1\n",
    "fs = 11\n",
    "##bin the probabilities\n",
    "counts_neg_train, edges_neg_train = np.histogram(p_train[:,0], bins=bins)\n",
    "counts_pos_train, edges_pos_train = np.histogram(p_train[:,1], bins=bins)\n",
    "\n",
    "counts_neg_val, edges_neg_val = np.histogram(p_val[:,0], bins=bins)\n",
    "counts_pos_val, edges_pos_val = np.histogram(p_val[:,1], bins=bins)\n",
    "\n",
    "counts_neg_test, edges_neg_test = np.histogram(p_test[:,0], bins=bins)\n",
    "counts_pos_test, edges_pos_test = np.histogram(p_test[:,1], bins=bins)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(11,11))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "\n",
    "ax1.bar(edges_neg_train[:-1], counts_neg_train, width=np.diff(edges_neg_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "ax1.set_title('Negative', fontsize=fs+2)\n",
    "ax1.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "ax1.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax2.bar(edges_pos_train[:-1], counts_pos_train, width=np.diff(edges_pos_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "ax2.set_title('Positive', fontsize=fs+2)\n",
    "ax2.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "#ax2.set_ylabel('Count')\n",
    "\n",
    "ax3.bar(edges_neg_val[:-1], counts_neg_val, width=np.diff(edges_neg_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax3.set_title('Negative Validation Predictions', fontsize=fs)\n",
    "ax3.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "ax3.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax4.bar(edges_pos_val[:-1], counts_pos_val, width=np.diff(edges_pos_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax4.set_title('Positive Validation Predictions', fontsize=fs)\n",
    "ax4.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "#ax4.set_ylabel('Count')\n",
    "\n",
    "ax5.bar(edges_neg_test[:-1], counts_neg_test, width=np.diff(edges_neg_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax5.set_title('Negative Testing Predictions', fontsize=fs)\n",
    "ax5.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "ax5.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax6.bar(edges_pos_test[:-1], counts_pos_test, width=np.diff(edges_pos_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax6.set_title('Positive Testing Predictions', fontsize=fs)\n",
    "ax6.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "#ax6.set_ylabel('Count')\n",
    "\n",
    "plt.suptitle(\"Probability Distributions of Various Datasets Across 100 CVs for Predicting +14 day European Temp Anomalies, EOF RM\", fontsize=fs+4, x=0.525,y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/EurRF_probdistribRM_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try SHAP with this model\n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rf_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089be818",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)\n",
    "shap_obj = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1943722",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"SHAP Values for Negative Europe Temp Anomalies +14 Days Lead, EOF RF\",fontsize =14, y = 1.05)\n",
    "ax = shap.plots.beeswarm(shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "#ax.set_xlim(-0.3,0.3)  \n",
    "plt.savefig(\"./images/EOFRFshap_Eur_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c53dfb44",
   "metadata": {},
   "source": [
    "plt.title(\"SHAP Values for Classifying Positive Temp Anomalies +14 Days Lead\",fontsize =14, y = 1.05)\n",
    "ax = shap.plots.beeswarm(shap_obj[:,:,1], show = False) ##for positive classifications ... this is physically consistent!\n",
    "#ax.set_xlim(-0.2,0.2)\n",
    "#plt.savefig(\"RFshap_Pos_Pred_14days.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a193db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######bar plot for showing the distribution of confident predictions\n",
    "bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "##bin the testing 90th percentile accuracy data\n",
    "counts90, edges90 = np.histogram(test90_acc, bins=bins)\n",
    "countsfull, edgesfull = np.histogram(fulltest_acc, bins=bins)\n",
    "# Plot the full dataset\n",
    "#offset = 0.02  # Adjust this value if needed for better visibility\n",
    "plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "        edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "# Plot the 90th percentile\n",
    "plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "        edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "plt.xlabel('Accuracy',fontsize =14)\n",
    "plt.ylabel('Number of Models',fontsize =14)\n",
    "plt.legend()\n",
    "plt.title('Testing Prediction ACC Across 100 EOF RF Models, Europe',fontsize =15)\n",
    "plt.savefig(\"./images/EurEOFRF_PredACCtest_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correct positive\n",
    "posXtest = np.array(posXtest)\n",
    "#false positive\n",
    "FposXtest = np.array(FposXtest)\n",
    "#correct negative\n",
    "negXtest = np.array(negXtest)\n",
    "#false negative\n",
    "FnegXtest = np.array(FnegXtest)\n",
    "\n",
    "indexes = np.array(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average Num. of 10% Confident and Correct Postive Predictions: {np.mean(percpos)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and Correct Negative Predictions: {np.mean(percneg)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Postive Predictions: {np.mean(percFpos)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Negative Predictions: {np.mean(percFneg)* 100:.2f}%')\n",
    "print('#######################################################################')\n",
    "print(f'Average Num. of 10% Confident and Correct Predictions: {np.mean(percpos)* 100 + np.mean(percneg)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Predictions: {np.mean(percFpos)* 100 +np.mean(percFneg)* 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dccd0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "####now I wanna make these plots SO ... I am adding an index column on to X_test ... full version. \n",
    "X_test = input.iloc[(57*149):,:]\n",
    "ranges = np.array([x for x in range(0,745,1)])\n",
    "ranges = ranges.reshape(5,149) \n",
    "ranges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c54d6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ranges[0,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##export out files to make the next few plots w/o normalization\n",
    "#pickle.dump(ranges, open(\"range_indices_RF14.p\", 'wb'))\n",
    "pickle.dump(posXtest, open(\"posXtest_eur14_eof.p\", 'wb'))\n",
    "pickle.dump(FposXtest, open(\"FposXtest_eur14_eof.p\", 'wb'))\n",
    "pickle.dump(negXtest, open(\"negXtest_eur14_eof.p\", 'wb'))\n",
    "pickle.dump(FnegXtest, open(\"FnegXtest_eur14_eof.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996647a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
