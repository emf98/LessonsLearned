{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8057fac7",
   "metadata": {},
   "source": [
    "### Random Forest ... but make it with the EOFs because I can lol. \n",
    "\n",
    "7/23/2025"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bc31f9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda7277b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m \u001b[38;5;66;03m# statistical data visualization\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, RandomForestClassifier\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#relevant import statements\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import sample\n",
    "\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01986496",
   "metadata": {},
   "outputs": [],
   "source": [
    "##just to stop the excess number of warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e24fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import definitions from skill stat file\n",
    "from SkillStats_MOD import BSS\n",
    "from SkillStats_MOD import RAS\n",
    "from SkillStats_MOD import PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 135\n",
    "#switch to 149 for normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 14\n",
    "#0 if normal\n",
    "#this indicates setting the start date as November 2 rather than October 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load input data\n",
    "infile = open(\"../../REAL/reduced_data/PCs/U_14.p\",\"rb\",)\n",
    "U_PC = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "U_PC = U_PC.reshape(62,149,10)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../REAL/reduced_data/PCs/EHF_14.p\",\"rb\",)\n",
    "EHF_PC = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "EHF_PC = EHF_PC.reshape(62,149,45)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../REAL/reduced_data/PCs/GPH_14.p\",\"rb\",)\n",
    "GPH_PC = pickle.load(infile)  \n",
    "GPH_PC = GPH_PC.reshape(62,149,10)\n",
    "infile.close()\n",
    "\n",
    "##remove PC 1\n",
    "U_PC = U_PC[:, shift:, 1:]\n",
    "EHF_PC = EHF_PC[:, shift:, 1:]\n",
    "GPH_PC = GPH_PC[:, shift:, 1:]\n",
    "\n",
    "U_PC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create one array of PCs\n",
    "inputvar = np.concatenate((U_PC,EHF_PC,GPH_PC),axis=2) \n",
    "inp1 = inputvar.reshape((62*idx),62)\n",
    "\n",
    "##make pandas dataframe for RF\n",
    "inp = pd.DataFrame(inp1)\n",
    "\n",
    "#create pd datafram of selected feature columns.\n",
    "inp = inp[[1, 56, 0, 54, 9, 57, 2, 31, 26, 14, 20, 6, 11, 38, 21, 18, 15, 22, 12, 13]]\n",
    "#label columns of variables for input data\n",
    "col_names = ['U3', 'GPH4', 'U2', 'GPH2', 'EHF2', 'GPH5', 'U4', 'EHF24', 'EHF19', 'EHF7',\n",
    "            'EHF13', 'U8', 'EHF4', 'EHF31', 'EHF14', 'EHF11', 'EHF8', 'EHF15', 'EHF5', 'EHF6']\n",
    "\n",
    "inp.columns = col_names\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load output data file.\n",
    "#I can change this to represent any of the available temp regions. \n",
    "infile = open(\"../data/eur_anomtemps_reduced.p\",\"rb\",)\n",
    "temp = pickle.load(infile) \n",
    "infile.close()\n",
    "\n",
    "# load climo data\n",
    "infile = open(\"../data/eur_climoprob_reduced.p\",\"rb\",)\n",
    "climo = pickle.load(infile) \n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50944bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)\n",
    "print(climo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6caf13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.reshape(62,149) ##it was flattened, reshape it\n",
    "climo = climo.reshape(62,149,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cd238",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reshape again to introduce lag. \n",
    "output = temp[:,shift:].reshape(62*idx)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reshaping climo\n",
    "climo = climo[:,shift:,:].reshape(62*idx,2)\n",
    "climo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061499da",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4756b2",
   "metadata": {},
   "source": [
    "### Start Random Forest Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first ... split data into training/testing ...\n",
    "##this is just taking the first 58 years of data, leaving the remaining 5 for testing\n",
    "X_train = inp.iloc[:(52*idx),:]\n",
    "X_test = inp.iloc[(52*idx):,:]\n",
    "Y_train = output[:(52*idx)]\n",
    "Y_test = output[(52*idx):]\n",
    "\n",
    "val_subset = (10*idx) #index for subsetting validation data in cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f5515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "##next are some empty lists, as I love to do lol. \n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77efdf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists to save Accuracy\n",
    "acc_reg1_val = []\n",
    "acc_reg1_train = []\n",
    "acc_reg1_test = []\n",
    "\n",
    "##BSS Arrays, all of the skill scores have 200 rows\n",
    "#because that is how many cross-validations I will do for the model\n",
    "BSS_all= np.empty((n,))\n",
    "BSS_val= np.empty((n,))\n",
    "BSS_train= np.empty((n,))\n",
    "BSS_test= np.empty((n,))\n",
    "\n",
    "##RAS and PAS Arrays\n",
    "Prec_all= np.empty((n,2))\n",
    "Rec_all= np.empty((n,2))\n",
    "\n",
    "Prec_val= np.empty((n,2))\n",
    "Rec_val= np.empty((n,2))\n",
    "\n",
    "Prec_train= np.empty((n,2))\n",
    "Rec_train= np.empty((n,2))\n",
    "\n",
    "Prec_test= np.empty((n,2))\n",
    "Rec_test= np.empty((n,2))\n",
    "\n",
    "important = np.empty((n,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3cd1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#save probabilities\n",
    "p_test = []\n",
    "p_train = []\n",
    "p_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879bb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create initial regressor for rf to do feature selection \n",
    "rf_reg1 = RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386e2ba",
   "metadata": {},
   "source": [
    "In order for me to add in the appropriate skill scores, since this is a categorical classification, I had to create separate metrics with one hot encoding to calculate BSS/RAS/PAS. \n",
    "\n",
    "I also had to calculate the daily probability for each categorical classification, which is done in the temperature pre-processing file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##one-hot encoded outputs for the purpose of calculating probabilities\n",
    "import keras\n",
    "Y_all = keras.utils.to_categorical(output)\n",
    "Y_tes = keras.utils.to_categorical(Y_test)\n",
    "X_all = inp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79711361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make loop for cross validation \n",
    "for l in range(0,n):\n",
    "    print(\"Cross Val #:\"+str(l))\n",
    "    ##randomly choose a fraction of events for validation and training\n",
    "    start = random.randrange(len(X_train.iloc[:,0])-val_subset)\n",
    "    end = start+(val_subset)\n",
    "\n",
    "    climo_test = climo[(52*idx):,:]\n",
    "    climo_tr = climo[:(52*idx),:]\n",
    "    \n",
    "    X_val = inp.iloc[start:end,:]\n",
    "    Y_val = output[start:end]\n",
    "    climo_val = climo_tr[start:end,:]\n",
    "    \n",
    "    X_train1 = X_train.iloc[0:start]\n",
    "    Y_train1 = Y_train[0:start]\n",
    "    climo_train1 = climo_tr[0:start,:]\n",
    "    X_train2 = X_train.iloc[end:]\n",
    "    Y_train2 = Y_train[end:]\n",
    "    climo_train2 = climo_tr[end:,:]\n",
    "\n",
    "    ##concatenate all of these\n",
    "    X_tr = pd.concat([X_train1,X_train2], axis = 0)\n",
    "    Y_tr = np.concatenate((Y_train1,Y_train2))\n",
    "    climo_train = np.concatenate((climo_train1,climo_train2))\n",
    "    \n",
    "\n",
    "    #_______________________train the model_______________________________\n",
    "    #train rf\n",
    "    rf_reg1.fit(X_tr, Y_tr)\n",
    "    pred1 = rf_reg1.predict(X_all)\n",
    "    pred2 = rf_reg1.predict_proba(X_all)\n",
    "    \n",
    "    #prediction with validation data\n",
    "    pred_val1 = rf_reg1.predict(X_val)\n",
    "    pred_val2 = rf_reg1.predict_proba(X_val)\n",
    "    p_val.append(pred_val2)\n",
    "    acc_reg1_val.append(accuracy_score(Y_val, pred_val1))\n",
    "    \n",
    "    #prediction with training data\n",
    "    pred_train1 = rf_reg1.predict(X_tr)\n",
    "    pred_train2 = rf_reg1.predict_proba(X_tr)\n",
    "    p_train.append(pred_train2)\n",
    "    acc_reg1_train.append(accuracy_score(Y_tr, pred_train1))\n",
    "\n",
    "    #prediction with testing data\n",
    "    pred_test1 = rf_reg1.predict(X_test)\n",
    "    pred_test2 = rf_reg1.predict_proba(X_test)\n",
    "    p_test.append(pred_test2)\n",
    "    acc_reg1_test.append(accuracy_score(Y_test, pred_test1))\n",
    "   \n",
    "    #_______________________feature selection______________________________\n",
    "    #prepare to show relevant features by actually ... choosing them \n",
    "    selector = SelectFromModel(rf_reg1, threshold=\"mean\", max_features=None)\n",
    "    X_train_selected = selector.transform(X_tr)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    #print names of selected features\n",
    "    selected_features = inp.columns[selector.get_support()]\n",
    "    print(f'Selected Features: {selected_features}')\n",
    "\n",
    "    importances = rf_reg1.feature_importances_\n",
    "    important[l,:] = importances[:]\n",
    "    \n",
    "    #_______________________statistics calcs_______________________________\n",
    "    pred_class = []\n",
    "    predval_class = []\n",
    "    predtr_class = []\n",
    "    predtest_class = []\n",
    "    \n",
    "    Y_tr2 = keras.utils.to_categorical(Y_tr)\n",
    "    Y_val2 = keras.utils.to_categorical(Y_val)\n",
    "\n",
    "    ##BRIER SKILL SCORE\n",
    "    BSS_all[l] = BSS(Y_all,pred2)\n",
    "    BSS_val[l] = BSS(Y_val2,pred_val2)\n",
    "    BSS_train[l] = BSS(Y_tr2,pred_train2)\n",
    "    BSS_test[l] = BSS(Y_tes,pred_test2) \n",
    "    \n",
    "    ##RECALL ACCURACY SCORE    \n",
    "    RAS(l, Rec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Rec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Rec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Rec_test, Y_tes, pred_test2, predtest_class)\n",
    "    ##PRECISION ACCURACY SCORE     \n",
    "    PAS(l, Prec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Prec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Prec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Prec_test, Y_tes, pred_test2, predtest_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('###################################################')\n",
    "print(f'Accuracy, Validation: {np.mean(acc_reg1_val) * 100:.2f}%')\n",
    "print(f'Accuracy, Training: {np.mean(acc_reg1_train) * 100:.2f}%')\n",
    "print(f'Accuracy, Testing: {np.mean(acc_reg1_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "font = 16\n",
    "#loop through each member\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ticks = ['Full', 'Train', 'Val', 'Test'] #set tick numbers for dataset\n",
    "colors = ['lightcyan','indianred']\n",
    "ind = [2, 4, 6, 8]  # the x locations for the groups\n",
    "w = 0.3 #box-plot width\n",
    "labels = ['- Anom', '+ Anom '] #labels of quantiles\n",
    "\n",
    "\n",
    "##begin to go plot by plot ...\n",
    "#each plot has a separate plot function for each lead time. In these, the plots get each quantile plotted. \n",
    "plt.suptitle(\"Stat Scores for Predicting Sign of Europe Temp Anoms in Full EOF RF Model at 14-days Leadtime\",fontsize = 18) \n",
    "\n",
    "a1_0 = ax1.boxplot(BSS_all[:], positions= [2], widths=w, patch_artist=True)\n",
    "a1_5 = ax1.boxplot(BSS_train[:], positions=[4], widths=w, patch_artist=True)\n",
    "a1_10 = ax1.boxplot(BSS_val[:], positions=[6], widths=w, patch_artist=True)\n",
    "a1_14 = ax1.boxplot(BSS_test[:], positions=[7], widths=w, patch_artist=True)\n",
    "ax1.axhline(0, c='k', ls ='-.')\n",
    "ax1.set_xticks(ind, ticks)\n",
    "#next few lines color the box plot faces\n",
    "for bplot in (a1_0, a1_5, a1_10, a1_14,):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "#for patch, label in zip(a1_0['boxes'], labels):\n",
    "    #patch.set_label(label)\n",
    "ax1.set_title('BSS for Temperature Region',fontsize = 14)\n",
    "ax1.set_ylim(-0.1,0.25)\n",
    "ax1.set_xlabel('Data Set',fontsize = 14)\n",
    "ax1.set_ylabel('BSS',fontsize = font)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax1.legend(loc = 'lower right', fontsize = 10)\n",
    "ax1.set_aspect('auto') ;\n",
    "\n",
    "##repeat the process\n",
    "a2_0 = ax2.boxplot([Rec_all[:,0],Rec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a2_5 = ax2.boxplot([Rec_train[:,0],Rec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a2_10 = ax2.boxplot([Rec_val[:,0],Rec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a2_14 = ax2.boxplot([Rec_test[:,0],Rec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax2.axhline(0.5, c='k', ls ='-.')\n",
    "ax2.set_xticks(ind, ticks)\n",
    "for bplot in (a2_0, a2_5, a2_10, a2_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a2_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax2.set_title('RAS for Temperature Region',fontsize = 14)\n",
    "ax2.set_ylim(-0.1,1.1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax2.set_ylabel('RAS',fontsize = font)\n",
    "#ax2.set_xlabel('Data Set',fontsize = 14)\n",
    "#ax2.set_ylabel('Brier Skill Score')\n",
    "ax2.legend(loc = 'lower right', fontsize = 14)\n",
    "ax2.set_aspect('auto') ;\n",
    "\n",
    "a3_0 = ax3.boxplot([Prec_all[:,0],Prec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a3_5 = ax3.boxplot([Prec_train[:,0],Prec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a3_10 = ax3.boxplot([Prec_val[:,0],Prec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a3_14 = ax3.boxplot([Prec_test[:,0],Prec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax3.axhline(0.5, c='k', ls ='-.')\n",
    "ax3.set_xticks(ind, ticks)\n",
    "for bplot in (a3_0, a3_5, a3_10, a3_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a3_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax3.set_title('RAS Well')\n",
    "#ax3.set_title('PAS for Temperature Region',fontsize = 14)\n",
    "ax3.set_ylim(-0.1,1.1)\n",
    "ax3.set_ylabel('PAS',fontsize = font)\n",
    "ax3.set_xlabel('Data Set',fontsize = font)\n",
    "#ax3.set_ylabel('Recall Accuracy Score',fontsize = 14)\n",
    "ax3.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax3.legend(loc = 'lower right', fontsize = 14)\n",
    "ax3.set_aspect('auto') ;\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"./images/FullEOFRF_14days_EurSS.png\", bbox_inches='tight',dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array(p_test)\n",
    "p_test = p_test.reshape((len(p_test)*len(p_test[0]),2))\n",
    "\n",
    "p_train = np.array(p_train)\n",
    "p_train = p_train.reshape((len(p_train)*len(p_train[0]),2))\n",
    "\n",
    "p_val= np.array(p_val)\n",
    "p_val = p_val.reshape((len(p_val)*len(p_val[0]),2))\n",
    "\n",
    "bins = np.linspace(0, 1, 37)  #10 bins from 0.4 to 1\n",
    "fs = 11\n",
    "##bin the probabilities\n",
    "counts_neg_train, edges_neg_train = np.histogram(p_train[:,0], bins=bins)\n",
    "counts_pos_train, edges_pos_train = np.histogram(p_train[:,1], bins=bins)\n",
    "\n",
    "counts_neg_val, edges_neg_val = np.histogram(p_val[:,0], bins=bins)\n",
    "counts_pos_val, edges_pos_val = np.histogram(p_val[:,1], bins=bins)\n",
    "\n",
    "counts_neg_test, edges_neg_test = np.histogram(p_test[:,0], bins=bins)\n",
    "counts_pos_test, edges_pos_test = np.histogram(p_test[:,1], bins=bins)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(11,11))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "\n",
    "ax1.bar(edges_neg_train[:-1], counts_neg_train, width=np.diff(edges_neg_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "ax1.set_title('Negative', fontsize=fs+2)\n",
    "ax1.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "ax1.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax2.bar(edges_pos_train[:-1], counts_pos_train, width=np.diff(edges_pos_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "ax2.set_title('Positive', fontsize=fs+2)\n",
    "ax2.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "#ax2.set_ylabel('Count')\n",
    "\n",
    "ax3.bar(edges_neg_val[:-1], counts_neg_val, width=np.diff(edges_neg_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax3.set_title('Negative Validation Predictions', fontsize=fs)\n",
    "ax3.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "ax3.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax4.bar(edges_pos_val[:-1], counts_pos_val, width=np.diff(edges_pos_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax4.set_title('Positive Validation Predictions', fontsize=fs)\n",
    "ax4.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "#ax4.set_ylabel('Count')\n",
    "\n",
    "ax5.bar(edges_neg_test[:-1], counts_neg_test, width=np.diff(edges_neg_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax5.set_title('Negative Testing Predictions', fontsize=fs)\n",
    "ax5.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "ax5.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax6.bar(edges_pos_test[:-1], counts_pos_test, width=np.diff(edges_pos_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax6.set_title('Positive Testing Predictions', fontsize=fs)\n",
    "ax6.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "#ax6.set_ylabel('Count')\n",
    "\n",
    "plt.suptitle(\"Probability Distributions of Various Datasets Across 100 CVs for Predicting +14 day European Temp Anomalies, EOF FM\", fontsize=fs+4, x=0.525,y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/EurEOFRF_probdistrib_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take average across all feature importance values by cross validation\n",
    "imp = np.nanmean(important, axis = 0)\n",
    "imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot features by relative importance\n",
    "indices = np.argsort(imp)[::-1]  #sort by importance\n",
    "c = [\"navy\",\"royalblue\",\"slateblue\",\"blueviolet\",\"darkviolet\",\"purple\",\"mediumvioletred\",\"magenta\"]\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(\"Average Feature Importances Across 100 CVs EOF RF, Europe 14\",fontsize =18)\n",
    "plt.barh(range(inp.shape[1]), imp[indices], align=\"center\", color = c)\n",
    "plt.yticks(range(inp.shape[1]), inp.columns[indices],fontsize =14)\n",
    "plt.xticks(fontsize =14)\n",
    "plt.xlabel(\"Relative Importance\",fontsize =16)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"./images/EurEOFRF_FeatureImportance_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371b0f2",
   "metadata": {},
   "source": [
    "### Switch over to the reduced model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "##change pandas dataframe to choose top 3 important features only\n",
    "#input2 = inp[['U3', \"GPH4\", \"GPH2\",\"U2\",\"EHF2\",\"EHF24\"]]\n",
    "input2 = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f7383",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#AGAIN, empty lists \n",
    "n = 100\n",
    "#empty lists to save Accuracy\n",
    "acc_reg2_val = []\n",
    "acc_reg2_train = []\n",
    "acc_reg2_test = []\n",
    "\n",
    "##BSS Arrays\n",
    "##BSS Arrays, all of the skill scores have 200 rows\n",
    "#because that is how many cross-validations I will do for the model\n",
    "BSS_all= np.empty((n,))\n",
    "BSS_val= np.empty((n,))\n",
    "BSS_train= np.empty((n,))\n",
    "BSS_test= np.empty((n,))\n",
    "\n",
    "##RAS and PAS Arrays\n",
    "Prec_all= np.empty((n,2))\n",
    "Rec_all= np.empty((n,2))\n",
    "\n",
    "Prec_val= np.empty((n,2))\n",
    "Rec_val= np.empty((n,2))\n",
    "\n",
    "Prec_train= np.empty((n,2))\n",
    "Rec_train= np.empty((n,2))\n",
    "\n",
    "Prec_test= np.empty((n,2))\n",
    "Rec_test= np.empty((n,2))\n",
    "\n",
    "important = np.empty((n,8))\n",
    "\n",
    "#save PREDICTIONS\n",
    "test90_acc = []\n",
    "##full model\n",
    "fulltest_acc = []\n",
    "\n",
    "##correct positive\n",
    "posXtest = []\n",
    "#false positive\n",
    "FposXtest = []\n",
    "#correct negative\n",
    "negXtest = []\n",
    "#false negative\n",
    "FnegXtest = []\n",
    "\n",
    "indexes = []\n",
    "\n",
    "##correct positive\n",
    "percpos = []\n",
    "#false positive\n",
    "percFpos = []\n",
    "#correct negative\n",
    "percneg = []\n",
    "#false negative\n",
    "percFneg = []\n",
    "\n",
    "#save probabilities\n",
    "p_test = []\n",
    "p_train = []\n",
    "p_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first ... split data into training/testing ...\n",
    "##this is just taking the first 58 years of data, leaving the remaining 5 for testing\n",
    "X_train = input2.iloc[:(52*idx),:]\n",
    "X_test = input2.iloc[(52*idx):,:]\n",
    "Y_train = output[:(52*idx)]\n",
    "Y_test = output[(52*idx):]\n",
    "\n",
    "val_subset = (10*idx) #index for subsetting validation data in cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "##definition statement for ACC\n",
    "def calculate_accuracy(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7006237",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = keras.utils.to_categorical(output)\n",
    "Y_tes = keras.utils.to_categorical(Y_test)\n",
    "X_all = input2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second random forest model with selected features only\n",
    "rf_reg2 = RandomForestClassifier(max_depth=3, n_estimators=400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4f63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make loop for cross validation \n",
    "for l in range(0,n):\n",
    "    print(\"Cross Val #:\"+str(l))\n",
    "    ##randomly choose a fraction of events for validation and training\n",
    "    start = random.randrange(len(X_train.iloc[:,0])-val_subset)\n",
    "    end = start+(val_subset)\n",
    "\n",
    "    climo_test = climo[(52*idx):,:]\n",
    "    climo_tr = climo[:(52*idx),:]\n",
    "    \n",
    "    X_val = input2.iloc[start:end,:]\n",
    "    Y_val = output[start:end]\n",
    "    climo_val = climo_tr[start:end,:]\n",
    "    \n",
    "    X_train1 = X_train.iloc[0:start]\n",
    "    Y_train1 = Y_train[0:start]\n",
    "    climo_train1 = climo_tr[0:start,:]\n",
    "    X_train2 = X_train.iloc[end:]\n",
    "    Y_train2 = Y_train[end:]\n",
    "    climo_train2 = climo_tr[end:,:]\n",
    "\n",
    "    ##concatenate all of these\n",
    "    X_tr = pd.concat([X_train1,X_train2], axis = 0)\n",
    "    Y_tr = np.concatenate((Y_train1,Y_train2))\n",
    "    climo_train = np.concatenate((climo_train1,climo_train2))\n",
    "    \n",
    "    \n",
    "    #_______________________train the model_______________________________\n",
    "    #train rf\n",
    "    rf_reg2.fit(X_tr, Y_tr)\n",
    "    pred1 = rf_reg2.predict(X_all)\n",
    "    pred2 = rf_reg2.predict_proba(X_all)\n",
    "    \n",
    "    #prediction with validation data\n",
    "    pred_val1 = rf_reg2.predict(X_val)\n",
    "    pred_val2 = rf_reg2.predict_proba(X_val)\n",
    "    p_val.append(pred_val2)\n",
    "    acc_reg2_val.append(accuracy_score(Y_val, pred_val1))\n",
    "    \n",
    "    #prediction with training data\n",
    "    pred_train1 = rf_reg2.predict(X_tr)\n",
    "    pred_train2 = rf_reg2.predict_proba(X_tr)\n",
    "    p_train.append(pred_train2)\n",
    "    acc_reg2_train.append(accuracy_score(Y_tr, pred_train1))\n",
    "\n",
    "    #prediction with testing data\n",
    "    pred_test1 = rf_reg2.predict(X_test)\n",
    "    pred_test2 = rf_reg2.predict_proba(X_test)\n",
    "    p_test.append(pred_test2)\n",
    "    acc_reg2_test.append(accuracy_score(Y_test, pred_test1))\n",
    "    \n",
    "    #_______________________statistics calcs_______________________________\n",
    "    pred_class = []\n",
    "    predval_class = []\n",
    "    predtr_class = []\n",
    "    predtest_class = []\n",
    "\n",
    "    Y_tr2 = keras.utils.to_categorical(Y_tr)\n",
    "    Y_val2 = keras.utils.to_categorical(Y_val)\n",
    "\n",
    "    ##BRIER SKILL SCORE\n",
    "    BSS_all[l] = BSS(Y_all,pred2)\n",
    "    BSS_val[l] = BSS(Y_val2,pred_val2)\n",
    "    BSS_train[l] = BSS(Y_tr2,pred_train2)\n",
    "    BSS_test[l] = BSS(Y_tes,pred_test2) \n",
    "    \n",
    "    ##RECALL ACCURACY SCORE    \n",
    "    RAS(l, Rec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Rec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Rec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Rec_test, Y_tes, pred_test2, predtest_class)\n",
    "    ##PRECISION ACCURACY SCORE     \n",
    "    PAS(l, Prec_all, climo, Y_all, pred2, pred_class,\n",
    "            climo_val, Prec_val, Y_val2, pred_val2, predval_class,\n",
    "            climo_train, Prec_train, Y_tr2, pred_train2, predtr_class,\n",
    "            climo_test, Prec_test, Y_tes, pred_test2, predtest_class)\n",
    "    \n",
    "    #___________________________Higher confidence samples_______________________\n",
    "\n",
    "    q90 = np.percentile(pred_test2,90,axis=0) ##90th percentile of test\n",
    "    ##90th percentile acc\n",
    "    great90 = [i for i, row in enumerate(pred_test2) if (row[0] > q90[0]) or (row[1] > q90[1])]\n",
    "    # Create the arrays of probabilities and actual values that exceed the 90th percentile\n",
    "    test90 = pred_test2[great90]\n",
    "    test90_norm = Y_tes[great90]\n",
    "    test90_acc.append(calculate_accuracy(test90_norm, test90, threshold=0.5))\n",
    "    ##full model\n",
    "    fulltest_acc.append(calculate_accuracy(Y_tes, pred_test2, threshold=0.5))\n",
    "\n",
    "    ##classify the accuracy of predicitons\n",
    "    correct_pos = [] #correct positive anomaly\n",
    "    correct_neg = [] #correct negative anomaly\n",
    "    \n",
    "    false_pos = [] #false positive\n",
    "    false_neg = [] #false negative\n",
    "\n",
    "    indexes.extend(great90)\n",
    "     for j in range(len(great90)):\n",
    "        index = great90[j]\n",
    "\n",
    "        if pred_test2[index, 1] > pred_test2[index, 0] and Y_tes[index, 1] == 1:\n",
    "            correct_pos.append(index)\n",
    "        elif pred_test2[index, 0] > pred_test2[index, 1] and Y_tes[index, 0] == 1:\n",
    "            correct_neg.append(index)\n",
    "        elif pred_test2[index, 1] > pred_test2[index, 0] and Y_tes[index, 0] == 1:\n",
    "            false_pos.append(index)\n",
    "        elif pred_test2[index, 0] > pred_test2[index, 1] and Y_tes[index, 1] == 1:\n",
    "            false_neg.append(index)\n",
    "\n",
    "    ##correct positive\n",
    "    posXtest.extend(correct_pos)\n",
    "    #false positive\n",
    "    FposXtest.extend(false_pos)\n",
    "    #correct negative\n",
    "    negXtest.extend(correct_neg)\n",
    "    #false negative\n",
    "    FnegXtest.extend(false_neg)\n",
    "    \n",
    "    percpos.append(len(correct_pos)/len(great90))\n",
    "    #false positive\n",
    "    percFpos.append(len(false_pos)/len(great90))\n",
    "    #correct negative\n",
    "    percneg.append(len(correct_neg)/len(great90))\n",
    "    #false negative\n",
    "    percFneg.append(len(false_neg)/len(great90))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('###################################################')\n",
    "print(f'Accuracy, Validation: {np.mean(acc_reg2_val) * 100:.2f}%')\n",
    "print(f'Accuracy, Training: {np.mean(acc_reg2_train) * 100:.2f}%')\n",
    "print(f'Accuracy, Testing: {np.mean(acc_reg2_test) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "font = 16\n",
    "#loop through each member\n",
    "ax1 = plt.subplot(3,1,1)\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ticks = ['Full', 'Train', 'Val', 'Test'] #set tick numbers for dataset\n",
    "colors = ['lightcyan','indianred']\n",
    "ind = [2, 4, 6, 8]  # the x locations for the groups\n",
    "w = 0.3 #box-plot width\n",
    "labels = ['- Anom', '+ Anom '] #labels of quantiles\n",
    "\n",
    "\n",
    "##begin to go plot by plot ...\n",
    "#each plot has a separate plot function for each lead time. In these, the plots get each quantile plotted. \n",
    "plt.suptitle(\"Stat Scores for Predicting Sign of Europe Temp Anoms in Reduced EOF RF Model at 14-days Leadtime\",fontsize = 18) \n",
    "\n",
    "a1_0 = ax1.boxplot(BSS_all[:], positions= [2], widths=w, patch_artist=True)\n",
    "a1_5 = ax1.boxplot(BSS_train[:], positions=[4], widths=w, patch_artist=True)\n",
    "a1_10 = ax1.boxplot(BSS_val[:], positions=[6], widths=w, patch_artist=True)\n",
    "a1_14 = ax1.boxplot(BSS_test[:], positions=[7], widths=w, patch_artist=True)\n",
    "ax1.axhline(0, c='k', ls ='-.')\n",
    "ax1.set_xticks(ind, ticks)\n",
    "#next few lines color the box plot faces\n",
    "for bplot in (a1_0, a1_5, a1_10, a1_14,):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "#for patch, label in zip(a1_0['boxes'], labels):\n",
    "    #patch.set_label(label)\n",
    "ax1.set_title('BSS for Temperature Region',fontsize = 14)\n",
    "ax1.set_ylim(-0.1,0.25)\n",
    "ax1.set_xlabel('Data Set',fontsize = 14)\n",
    "ax1.set_ylabel('BSS',fontsize = font)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax1.legend(loc = 'lower right', fontsize = 10)\n",
    "ax1.set_aspect('auto') ;\n",
    "\n",
    "##repeat the process\n",
    "a2_0 = ax2.boxplot([Rec_all[:,0],Rec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a2_5 = ax2.boxplot([Rec_train[:,0],Rec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a2_10 = ax2.boxplot([Rec_val[:,0],Rec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a2_14 = ax2.boxplot([Rec_test[:,0],Rec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax2.axhline(0.5, c='k', ls ='-.')\n",
    "ax2.set_xticks(ind, ticks)\n",
    "for bplot in (a2_0, a2_5, a2_10, a2_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a2_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax2.set_title('RAS for Temperature Region',fontsize = 14)\n",
    "ax2.set_ylim(-0.1,1.1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax2.set_ylabel('RAS',fontsize = font)\n",
    "#ax2.set_xlabel('Data Set',fontsize = 14)\n",
    "#ax2.set_ylabel('Brier Skill Score')\n",
    "ax2.legend(loc = 'lower right', fontsize = 14)\n",
    "ax2.set_aspect('auto') ;\n",
    "\n",
    "a3_0 = ax3.boxplot([Prec_all[:,0],Prec_all[:,1]], positions= [1.8,2.2], widths=w, patch_artist=True)\n",
    "a3_5 = ax3.boxplot([Prec_train[:,0],Prec_train[:,1]], positions=[3.8,4.2], widths=w, patch_artist=True)\n",
    "a3_10 = ax3.boxplot([Prec_val[:,0],Prec_val[:,1]], positions=[5.8,6.2], widths=w, patch_artist=True)\n",
    "a3_14 = ax3.boxplot([Prec_test[:,0],Prec_test[:,1]], positions=[7.8,8.2], widths=w, patch_artist=True)\n",
    "ax3.axhline(0.5, c='k', ls ='-.')\n",
    "ax3.set_xticks(ind, ticks)\n",
    "for bplot in (a3_0, a3_5, a3_10, a3_14):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "for patch, label in zip(a3_0['boxes'], labels):\n",
    "    patch.set_label(label)\n",
    "#ax3.set_title('RAS Well')\n",
    "#ax3.set_title('PAS for Temperature Region',fontsize = 14)\n",
    "ax3.set_ylim(-0.1,1.1)\n",
    "ax3.set_ylabel('PAS',fontsize = font)\n",
    "ax3.set_xlabel('Data Set',fontsize = font)\n",
    "#ax3.set_ylabel('Recall Accuracy Score',fontsize = 14)\n",
    "ax3.tick_params(axis='both', which='major', labelsize= font)\n",
    "ax3.legend(loc = 'lower right', fontsize = 14)\n",
    "ax3.set_aspect('auto') ;\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"./images/RedEOFRF_14days_EurSS.png\", bbox_inches='tight',dpi =150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.array(p_test)\n",
    "p_test = p_test.reshape((len(p_test)*len(p_test[0]),2))\n",
    "\n",
    "p_train = np.array(p_train)\n",
    "p_train = p_train.reshape((len(p_train)*len(p_train[0]),2))\n",
    "\n",
    "p_val= np.array(p_val)\n",
    "p_val = p_val.reshape((len(p_val)*len(p_val[0]),2))\n",
    "\n",
    "bins = np.linspace(0, 1, 37)  #10 bins from 0.4 to 1\n",
    "fs = 11\n",
    "##bin the probabilities\n",
    "counts_neg_train, edges_neg_train = np.histogram(p_train[:,0], bins=bins)\n",
    "counts_pos_train, edges_pos_train = np.histogram(p_train[:,1], bins=bins)\n",
    "\n",
    "counts_neg_val, edges_neg_val = np.histogram(p_val[:,0], bins=bins)\n",
    "counts_pos_val, edges_pos_val = np.histogram(p_val[:,1], bins=bins)\n",
    "\n",
    "counts_neg_test, edges_neg_test = np.histogram(p_test[:,0], bins=bins)\n",
    "counts_pos_test, edges_pos_test = np.histogram(p_test[:,1], bins=bins)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(11,11))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes.flatten()\n",
    "\n",
    "ax1.bar(edges_neg_train[:-1], counts_neg_train, width=np.diff(edges_neg_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "ax1.set_title('Negative', fontsize=fs+2)\n",
    "ax1.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "ax1.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax2.bar(edges_pos_train[:-1], counts_pos_train, width=np.diff(edges_pos_train), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "ax2.set_title('Positive', fontsize=fs+2)\n",
    "ax2.set_xlabel('Probability in Training Data', fontsize=fs+1)\n",
    "#ax2.set_ylabel('Count')\n",
    "\n",
    "ax3.bar(edges_neg_val[:-1], counts_neg_val, width=np.diff(edges_neg_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax3.set_title('Negative Validation Predictions', fontsize=fs)\n",
    "ax3.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "ax3.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax4.bar(edges_pos_val[:-1], counts_pos_val, width=np.diff(edges_pos_val), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax4.set_title('Positive Validation Predictions', fontsize=fs)\n",
    "ax4.set_xlabel('Probability in Validation Data', fontsize=fs+1)\n",
    "#ax4.set_ylabel('Count')\n",
    "\n",
    "ax5.bar(edges_neg_test[:-1], counts_neg_test, width=np.diff(edges_neg_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='blue')\n",
    "#ax5.set_title('Negative Testing Predictions', fontsize=fs)\n",
    "ax5.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "ax5.set_ylabel('Count', fontsize=fs+1)\n",
    "\n",
    "ax6.bar(edges_pos_test[:-1], counts_pos_test, width=np.diff(edges_pos_test), \n",
    "        edgecolor='black', alpha=0.5, align='edge', color='orange')\n",
    "#ax6.set_title('Positive Testing Predictions', fontsize=fs)\n",
    "ax6.set_xlabel('Probability in Testing Data', fontsize=fs+1)\n",
    "#ax6.set_ylabel('Count')\n",
    "\n",
    "plt.suptitle(\"Probability Distributions of Various Datasets Across 100 CVs for Predicting +14 day European Temp Anomalies, EOF RM\", fontsize=fs+4, x=0.525,y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/EurRF_probdistribRM_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c476479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try SHAP with this model\n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rf_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)\n",
    "shap_obj = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbe356",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879332a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"SHAP Values for Negative Europe Temp Anomalies +14 Days Lead, EOF RF\",fontsize =14, y = 1.05)\n",
    "ax = shap.plots.beeswarm(shap_obj[:,:,0], show = False) ##for negative classifications ... this is physically consistent!\n",
    "#ax.set_xlim(-0.3,0.3)  \n",
    "plt.savefig(\"./images/EOFRFshap_Eur_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c985ec20",
   "metadata": {},
   "source": [
    "plt.title(\"SHAP Values for Classifying Positive Temp Anomalies +14 Days Lead\",fontsize =14, y = 1.05)\n",
    "ax = shap.plots.beeswarm(shap_obj[:,:,1], show = False) ##for positive classifications ... this is physically consistent!\n",
    "#ax.set_xlim(-0.2,0.2)\n",
    "#plt.savefig(\"RFshap_Pos_Pred_14days.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02781371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######bar plot for showing the distribution of confident predictions\n",
    "bins = np.linspace(0.4, 1,13)  # 10 bins from 0.4 to 1\n",
    "##bin the testing 90th percentile accuracy data\n",
    "counts90, edges90 = np.histogram(test90_acc, bins=bins)\n",
    "countsfull, edgesfull = np.histogram(fulltest_acc, bins=bins)\n",
    "# Plot the full dataset\n",
    "#offset = 0.02  # Adjust this value if needed for better visibility\n",
    "plt.bar(edgesfull[:-1], countsfull, width=np.diff(edgesfull), \n",
    "        edgecolor='black', alpha=0.5, label='All Predictions', align='edge', color='blue')\n",
    "# Plot the 90th percentile\n",
    "plt.bar(edges90[:-1], counts90, width=np.diff(edges90), \n",
    "        edgecolor='black', alpha=0.5, label='>90th Percentile Predictions', align='edge', color = 'lightblue')\n",
    "plt.xlabel('Accuracy',fontsize =14)\n",
    "plt.ylabel('Number of Models',fontsize =14)\n",
    "plt.legend()\n",
    "plt.title('Testing Prediction ACC Across 100 EOF RF Models, Europe',fontsize =15)\n",
    "plt.savefig(\"./images/EurEOFRF_PredACCtest_14days.png\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##correct positive\n",
    "posXtest = np.array(posXtest)\n",
    "#false positive\n",
    "FposXtest = np.array(FposXtest)\n",
    "#correct negative\n",
    "negXtest = np.array(negXtest)\n",
    "#false negative\n",
    "FnegXtest = np.array(FnegXtest)\n",
    "\n",
    "indexes = np.array(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be260b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average Num. of 10% Confident and Correct Postive Predictions: {np.mean(percpos)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and Correct Negative Predictions: {np.mean(percneg)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Postive Predictions: {np.mean(percFpos)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Negative Predictions: {np.mean(percFneg)* 100:.2f}%')\n",
    "print('#######################################################################')\n",
    "print(f'Average Num. of 10% Confident and Correct Predictions: {np.mean(percpos)* 100 + np.mean(percneg)* 100:.2f}%')\n",
    "print(f'Average Num. of 10% Confident and FALSE Predictions: {np.mean(percFpos)* 100 +np.mean(percFneg)* 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##export out files to make the next few plots w/o normalization\n",
    "#pickle.dump(ranges, open(\"range_indices_RF14.p\", 'wb'))\n",
    "pickle.dump(posXtest, open(\"posXtest_eur14_eof.p\", 'wb'))\n",
    "pickle.dump(FposXtest, open(\"FposXtest_eur14_eof.p\", 'wb'))\n",
    "pickle.dump(negXtest, open(\"negXtest_eur14_eof.p\", 'wb'))\n",
    "pickle.dump(FnegXtest, open(\"FnegXtest_eur14_eof.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4fb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9f0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
